{"cells": [{"cell_type": "markdown", "id": "aad4e28d", "metadata": {}, "source": ["# 坚持\n", "\n", "许多人工智能应用程序需要内存来在单个会话“线程”中的多个交互之间共享上下文。\n", "在 LangGraph 中，这种类型的会话级内存可以使用以下方式添加到任何图形中：\n", "[检查点](https://langchain-ai.github.io/langgraphjs/reference/interfaces/index.Checkpoint.html)。\n", "\n", "只需使用兼容的检查点编译图表即可。下面是使用简单内存中“MemorySaver”的示例：\n", "```javascript\n", "import { MemorySaver } from \"@langchain/langgraph\";\n", "\n", "const checkpointer = new MemorySaver();\n", "const graph = workflow.compile({ checkpointer });\n", "```\n", "本指南展示了如何将线程级持久性添加到图表中。\n", "\n", "<div class=\"警告提示\">\n", "<p class=\"admonition-title\">注意：多对话记忆</p>\n", "<p>\n", "如果您需要在多个对话或用户之间<b>共享</b>内存（跨线程持久性），请查看此<a href=\"https://langchain-ai.github.io/langgraphjs/how-tos/cross-thread-persistence/\">操作指南</a>）。\n", "</p>\n", "</div>\n", "\n", "<div class=\"警告提示\">\n", "<p class=\"admonition-title\">注意</p>\n", "<p>\n", "在本指南中，我们将从头开始创建透明（但冗长）的代理。您可以使用 <code>createReactAgent(model, tools=tool, checkpointer=checkpointer)</code> (<a href=\"https://langchain-ai.github.io/langgraphjs/reference/functions/prebuilt.createReactAgent.html\">API doc</a>) 构造函数完成类似的功能。如果你习惯了 LangChain 的 <a href=\"https://js.langchain.com/docs/how_to/agent_executor\">AgentExecutor</a> 类，这可能更合适。\n", "</p>\n", "</div>\n", "\n", "## 设置\n", "\n", "本指南将使用 OpenAI 的 GPT-4o 模型。我们可以选择设置 API 密钥\n", "对于 [LangSmith 追踪](https://smith.langchain.com/)，这将为我们提供\n", "一流的可观测性。"]}, {"cell_type": "code", "execution_count": 1, "id": "10021b8c", "metadata": {"lines_to_next_cell": 2}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Persistence: LangGraphJS\n"]}], "source": ["// process.env.OPENAI_API_KEY = \"sk_...\";\n", "\n", "// 可选，在 LangSmith 中添加跟踪\n", "// process.env.LANGCHAIN_API_KEY = \"ls__...\";\n", "process.env.LANGCHAIN_CALLBACKS_BACKGROUND = \"true\";\n", "process.env.LANGCHAIN_TRACING_V2 = \"true\";\n", "process.env.LANGCHAIN_PROJECT = \"Persistence: LangGraphJS\";"]}, {"cell_type": "markdown", "id": "5b9e252c", "metadata": {}, "source": ["## 定义状态\n", "\n", "状态是图中所有节点的接口。\n"]}, {"cell_type": "code", "execution_count": 2, "id": "9fc47087", "metadata": {"lines_to_next_cell": 2}, "outputs": [], "source": ["import { Annotation } from \"@langchain/langgraph\";\n", "import { BaseMessage } from \"@langchain/core/messages\";\n", "\n", "const GraphState = Annotation.Root({\n", "  messages: Annotation<BaseMessage[]>({\n", "    reducer: (x, y) => x.concat(y),\n", "  }),\n", "});"]}, {"cell_type": "markdown", "id": "8bdba79f", "metadata": {}, "source": ["## 设置工具\n", "\n", "我们将首先定义我们想要使用的工具。对于这个简单的例子，我们将\n", "使用创建占位符搜索引擎。然而，创建起来确实很容易\n", "您自己的工具 - 请参阅文档\n", "[此处](https://js.langchain.com/docs/how_to/custom_tools) 了解如何操作\n", "那。"]}, {"cell_type": "code", "execution_count": 3, "id": "5f1e5deb", "metadata": {"lines_to_next_cell": 2}, "outputs": [], "source": ["import { tool } from \"@langchain/core/tools\";\n", "import { z } from \"zod\";\n", "\n", "const searchTool = tool(async ({}: { query: string }) => {\n", "  // 这是实际实现的占位符\n", "  return \"Cold, with a low of 13 ℃\";\n", "}, {\n", "  name: \"search\",\n", "  description:\n", "    \"Use to surf the web, fetch current information, check the weather, and retrieve other information.\",\n", "  schema: z.object({\n", "    query: z.string().describe(\"The query to use in your search.\"),\n", "  }),\n", "});\n", "\n", "await searchTool.invoke({ query: \"What's the weather like?\" });\n", "\n", "const tools = [searchTool];"]}, {"cell_type": "markdown", "id": "a5615fd8", "metadata": {}, "source": ["我们现在可以将这些工具包装在一个简单的\n", "[ToolNode](/langgraphjs/reference/classes/langgraph_prebuilt.ToolNode.html)。\n", "每当工具（函数）被调用时，该对象就会实际运行它们\n", "我们的法学硕士。"]}, {"cell_type": "code", "execution_count": 4, "id": "1852d2a4", "metadata": {"lines_to_next_cell": 2}, "outputs": [], "source": ["import { ToolNode } from \"@langchain/langgraph/prebuilt\";\n", "\n", "const toolNode = new ToolNode(tools);"]}, {"cell_type": "markdown", "id": "a593cc20", "metadata": {}, "source": ["## 设置模型\n", "\n", "现在我们将加载\n", "[聊天模型](https://js.langchain.com/docs/concepts/#chat-models)。\n", "\n", "1.它应该与消息一起使用。我们将以表格形式代表所有代理状态\n", "消息，因此它需要能够与它们很好地配合。\n", "2.它应该与\n", "[工具调用](https://js.langchain.com/docs/how_to/tool_calling/#passing-tools-to-llms),\n", "这意味着它可以在响应中返回函数参数。\n", "\n", "<div class=\"警告提示\">\n", "<p class=\"admonition-title\">注意</p>\n", "<p>\n", "这些模型要求不是使用 LangGraph 的一般要求 - 它们只是这个示例的要求。\n", "</p>\n", "</div>"]}, {"cell_type": "code", "execution_count": 5, "id": "77c9701b", "metadata": {"lines_to_next_cell": 2}, "outputs": [], "source": ["import { ChatOpenAI } from \"@langchain/openai\";\n", "\n", "const model = new ChatOpenAI({ model: \"gpt-4o\" });"]}, {"cell_type": "markdown", "id": "4177b143", "metadata": {}, "source": ["完成此操作后，我们应该确保模型知道它具有这些\n", "可供调用的工具。我们可以通过调用来做到这一点\n", "[bindTools](https://v01.api.js.langchain.com/classes/langchain_core_language_models_chat_models.BaseChatModel.html#bindTools)。"]}, {"cell_type": "code", "execution_count": 6, "id": "b35d9bd2", "metadata": {"lines_to_next_cell": 2}, "outputs": [], "source": ["const boundModel = model.bindTools(tools);"]}, {"cell_type": "markdown", "id": "bbb0ae12", "metadata": {}, "source": ["## 定义图表\n", "\n", "我们现在可以把它们放在一起。我们将首先在没有检查点的情况下运行它：\n"]}, {"cell_type": "code", "execution_count": 7, "id": "5f85457b", "metadata": {}, "outputs": [], "source": ["import { END, START, StateGraph } from \"@langchain/langgraph\";\n", "import { AIMessage } from \"@langchain/core/messages\";\n", "import { RunnableConfig } from \"@langchain/core/runnables\";\n", "\n", "const routeMessage = (state: typeof GraphState.State) => {\n", "  const { messages } = state;\n", "  const lastMessage = messages[messages.length - 1] as AIMessage;\n", "  // 如果没有调用任何工具，我们就可以完成（响应用户）\n", "  if (!lastMessage.tool_calls?.length) {\n", "    return END;\n", "  }\n", "  // 否则，如果有，我们继续并调用工具\n", "  return \"tools\";\n", "};\n", "\n", "const callModel = async (\n", "  state: typeof GraphState.State,\n", "  config?: RunnableConfig,\n", ") => {\n", "  const { messages } = state;\n", "  const response = await boundModel.invoke(messages, config);\n", "  return { messages: [response] };\n", "};\n", "\n", "const workflow = new StateGraph(GraphState)\n", "  .addNode(\"agent\", callModel)\n", "  .addNode(\"tools\", toolNode)\n", "  .addEdge(START, \"agent\")\n", "  .addConditionalEdges(\"agent\", routeMessage)\n", "  .addEdge(\"tools\", \"agent\");\n", "\n", "const graph = workflow.compile();"]}, {"cell_type": "code", "execution_count": 8, "id": "41364864", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Hi I'm Yu, nice to meet you.\n", "-----\n", "\n", "Hi Yu! Nice to meet you too. How can I assist you today?\n", "-----\n", "\n"]}], "source": ["let inputs = { messages: [{ role: \"user\", content: \"Hi I'm Yu, nice to meet you.\" }] };\n", "for await (\n", "  const { messages } of await graph.stream(inputs, {\n", "    streamMode: \"values\",\n", "  })\n", ") {\n", "  let msg = messages[messages?.length - 1];\n", "  if (msg?.content) {\n", "    console.log(msg.content);\n", "  } else if (msg?.tool_calls?.length > 0) {\n", "    console.log(msg.tool_calls);\n", "  } else {\n", "    console.log(msg);\n", "  }\n", "  console.log(\"-----\\n\");\n", "}"]}, {"cell_type": "code", "execution_count": 9, "id": "ccddfd4a", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Remember my name?\n", "-----\n", "\n", "You haven't shared your name with me yet. What's your name?\n", "-----\n", "\n"]}], "source": ["inputs = { messages: [{ role: \"user\", content: \"Remember my name?\" }] };\n", "for await (\n", "  const { messages } of await graph.stream(inputs, {\n", "    streamMode: \"values\",\n", "  })\n", ") {\n", "  let msg = messages[messages?.length - 1];\n", "  if (msg?.content) {\n", "    console.log(msg.content);\n", "  } else if (msg?.tool_calls?.length > 0) {\n", "    console.log(msg.tool_calls);\n", "  } else {\n", "    console.log(msg);\n", "  }\n", "  console.log(\"-----\\n\");\n", "}"]}, {"cell_type": "markdown", "id": "3bece060", "metadata": {}, "source": ["## 添加内存\n", "\n", "让我们用检查点再试一次。我们将使用\n", "[MemorySaver](/langgraphjs/reference/classes/index.MemorySaver.html),\n", "这将在内存中“保存”检查点。"]}, {"cell_type": "code", "execution_count": 10, "id": "217ac741", "metadata": {"lines_to_next_cell": 2}, "outputs": [], "source": ["import { MemorySaver } from \"@langchain/langgraph\";\n", "\n", "// 这里我们只保存在内存中\n", "const memory = new MemorySaver();\n", "const persistentGraph = workflow.compile({ checkpointer: memory });"]}, {"cell_type": "code", "execution_count": 11, "id": "173c17f9", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Hi I'm Jo, nice to meet you.\n", "-----\n", "\n", "Hello Jo, nice to meet you too! How can I assist you today?\n", "-----\n", "\n"]}], "source": ["let config = { configurable: { thread_id: \"conversation-num-1\" } };\n", "inputs = { messages: [{ role: \"user\", content: \"Hi I'm Jo, nice to meet you.\" }] };\n", "for await (\n", "  const { messages } of await persistentGraph.stream(inputs, {\n", "    ...config,\n", "    streamMode: \"values\",\n", "  })\n", ") {\n", "  let msg = messages[messages?.length - 1];\n", "  if (msg?.content) {\n", "    console.log(msg.content);\n", "  } else if (msg?.tool_calls?.length > 0) {\n", "    console.log(msg.tool_calls);\n", "  } else {\n", "    console.log(msg);\n", "  }\n", "  console.log(\"-----\\n\");\n", "}"]}, {"cell_type": "code", "execution_count": 12, "id": "1162eb84", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Remember my name?\n", "-----\n", "\n", "Yes, I'll remember that your name is Jo. How can I assist you today?\n", "-----\n", "\n"]}], "source": ["inputs = { messages: [{ role: \"user\", content: \"Remember my name?\"}] };\n", "for await (\n", "  const { messages } of await persistentGraph.stream(inputs, {\n", "    ...config,\n", "    streamMode: \"values\",\n", "  })\n", ") {\n", "  let msg = messages[messages?.length - 1];\n", "  if (msg?.content) {\n", "    console.log(msg.content);\n", "  } else if (msg?.tool_calls?.length > 0) {\n", "    console.log(msg.tool_calls);\n", "  } else {\n", "    console.log(msg);\n", "  }\n", "  console.log(\"-----\\n\");\n", "}"]}, {"cell_type": "markdown", "id": "73902faf", "metadata": {}, "source": ["## 新对话主题\n", "\n", "如果我们想开始一个新的对话，我们可以传入一个不同的\n", "**[[代码0]]**。噗！所有的记忆都消失了（开玩笑，他们永远都会\n", "住在另一个线程中）！\n"]}, {"cell_type": "code", "execution_count": 13, "id": "58cc0612", "metadata": {"lines_to_next_cell": 2}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["{ configurable: { thread_id: 'conversation-2' } }\n"]}], "source": ["config = { configurable: { thread_id: \"conversation-2\" } };"]}, {"cell_type": "code", "execution_count": 14, "id": "25aea87b", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["you forgot?\n", "-----\n", "\n"]}, {"name": "stdout", "output_type": "stream", "text": ["Could you please provide more context or details about what you are referring to? This will help me assist you better.\n", "-----\n", "\n"]}], "source": ["inputs = { messages: [{ role: \"user\", content: \"you forgot?\" }] };\n", "for await (\n", "  const { messages } of await persistentGraph.stream(inputs, {\n", "    ...config,\n", "    streamMode: \"values\",\n", "  })\n", ") {\n", "  let msg = messages[messages?.length - 1];\n", "  if (msg?.content) {\n", "    console.log(msg.content);\n", "  } else if (msg?.tool_calls?.length > 0) {\n", "    console.log(msg.tool_calls);\n", "  } else {\n", "    console.log(msg);\n", "  }\n", "  console.log(\"-----\\n\");\n", "}"]}], "metadata": {"jupytext": {"encoding": "# -*- coding: utf-8 -*-"}, "kernelspec": {"display_name": "TypeScript", "language": "typescript", "name": "tslab"}, "language_info": {"codemirror_mode": {"mode": "typescript", "name": "javascript", "typescript": true}, "file_extension": ".ts", "mimetype": "text/typescript", "name": "typescript", "version": "3.7.2"}}, "nbformat": 4, "nbformat_minor": 5}