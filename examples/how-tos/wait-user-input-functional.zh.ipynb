{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# 如何等待用户输入（函数式API）\n", "\n", "!!!信息“先决条件”\n", "本指南假设您熟悉以下内容：\n", "\n", "- 使用[中断](../../concepts/ human_in_the_loop/#interrupt) 实施[人机循环](../../concepts/ human_in_the_loop) 工作流程\n", "- [如何使用功能 API 创建 ReAct 代理](../../how-tos/react-agent-from-scratch-function)\n", "\n", "**人在环（HIL）**交互对于[代理系统]（../../concepts/agentic_concepts/# human-in-the-loop）至关重要。等待人工输入是一种常见的 HIL 交互模式，允许代理询问用户澄清问题并在继续之前等待输入。\n", "\n", "我们可以使用 [interrupt()](/langgraphjs/reference/functions/langgraph.interrupt-1.html) 函数在 LangGraph 中实现这一点。`interrupt` 允许我们停止图形执行以收集用户的输入，并使用收集的输入继续执行。\n", "\n", "本指南演示了如何使用 LangGraph 的 [Functional API](../../concepts/featured_api) 实现人机交互工作流程。具体来说，我们将演示：\n", "\n", "1. [简单使用示例](#simple-usage)\n", "2. [如何使用ReAct代理](#agent)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 设置\n", "\n", "!!!注意兼容性\n", "\n", "本指南需要 `@langchain/langgraph>=0.2.42`。\n", "\n", "首先，安装本示例所需的依赖项：\n", "```bash\n", "npm install @langchain/langgraph @langchain/openai @langchain/core zod\n", "```\n", "接下来，我们需要为 OpenAI 设置 API 密钥（我们将使用的 LLM）：\n", "```typescript\n", "process.env.OPENAI_API_KEY = \"YOUR_API_KEY\";\n", "```\n", "!!!提示“为 LangGraph 开发设置 [LangSmith](https://smith.langchain.com)”\n", "\n", "注册 LangSmith 以快速发现问题并提高 LangGraph 项目的性能。LangSmith 允许您使用跟踪数据来调试、测试和监控使用 LangGraph 构建的 LLM 应用程序 — 在[此处](https://docs.smith.langchain.com)了解有关如何开始的更多信息"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 简单用法\n", "\n", "让我们演示一个简单的使用示例。我们将创建三个[任务](../../concepts/featured_api/#task)：\n", "\n", "1. 追加`\"bar\"`。\n", "2. 暂停以等待人工输入。恢复时，附加人工输入。\n", "3. 追加[[代码1]]。"]}, {"cell_type": "code", "execution_count": 1, "metadata": {}, "outputs": [], "source": ["import { task, interrupt } from \"@langchain/langgraph\";\n", "\n", "const step1 = task(\"step1\", async (inputQuery: string) => {\n", "  return `${inputQuery} bar`;\n", "});\n", "\n", "const humanFeedback = task(\n", "  \"humanFeedback\",\n", "  async (inputQuery: string) => {\n", "    const feedback = interrupt(`Please provide feedback: ${inputQuery}`);\n", "    return `${inputQuery} ${feedback}`;\n", "  });\n", "\n", "const step3 = task(\"step3\", async (inputQuery: string) => {\n", "  return `${inputQuery} qux`;\n", "});"]}, {"cell_type": "markdown", "metadata": {}, "source": ["我们现在可以在一个简单的[entrypoint](../../concepts/featured_api/#entrypoint)中组合这些任务："]}, {"cell_type": "code", "execution_count": 2, "metadata": {}, "outputs": [], "source": ["import { MemorySaver, entrypoint } from \"@langchain/langgraph\";\n", "\n", "const checkpointer = new MemorySaver();\n", "\n", "const graph = entrypoint({\n", "  name: \"graph\",\n", "  checkpointer,\n", "}, async (inputQuery: string) => {\n", "  const result1 = await step1(inputQuery);\n", "  const result2 = await humanFeedback(result1);\n", "  const result3 = await step3(result2);\n", "  return result3;\n", "});"]}, {"cell_type": "markdown", "metadata": {}, "source": ["为了实现人机循环工作流程，我们所做的就是在任务内调用 [interrupt()](../../concepts/ human_in_the_loop/#interrupt) 。\n", "\n", "!!!提示\n", "\n", "先前任务的结果 - 在本例中为 `step1 -- are persisted, so that they are not run again following the `interrupt`。\n", "\n", "\n", "让我们发送一个查询字符串："]}, {"cell_type": "code", "execution_count": 3, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["{ step1: 'foo bar' }\n", "{\n", "  __interrupt__: [\n", "    {\n", "      value: 'Please provide feedback: foo bar',\n", "      when: 'during',\n", "      resumable: true,\n", "      ns: [Array]\n", "    }\n", "  ]\n", "}\n"]}], "source": ["const config = {\n", "  configurable: {\n", "    thread_id: \"1\"\n", "  }\n", "};\n", "\n", "const stream = await graph.stream(\"foo\", config);\n", "\n", "for await (const event of stream) {\n", "  console.log(event);\n", "}"]}, {"cell_type": "markdown", "metadata": {}, "source": ["请注意，我们在 `step1` 之后以 `interrupt` 暂停。中断提供恢复运行的指令。为了恢复，我们发出一个 [Command](../../concepts/ human_in_the_loop/#the-command-primitive) ，其中包含 `humanFeedback` 任务所需的数据。"]}, {"cell_type": "code", "execution_count": 4, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["{ humanFeedback: 'foo bar baz' }\n", "{ step3: 'foo bar baz qux' }\n", "{ graph: 'foo bar baz qux' }\n"]}], "source": ["import { Command } from \"@langchain/langgraph\";\n", "\n", "const resumeStream = await graph.stream(new Command({\n", "  resume: \"baz\"\n", "}), config);\n", "\n", "// 继续执行\n", "for await (const event of resumeStream) {\n", "  if (event.__metadata__?.cached) {\n", "    continue;\n", "  }\n", "  console.log(event);\n", "}"]}, {"cell_type": "markdown", "metadata": {}, "source": ["恢复后，运行将继续执行剩余步骤并按预期终止。"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 代理人\n", "\n", "我们将基于[如何使用功能 API 创建 ReAct 代理](../../how-tos/react-agent-from-scratch-function) 指南中创建的代理进行构建。\n", "\n", "在这里，我们将扩展代理，允许它在需要时向人类寻求帮助。\n", "\n", "### 定义模型和工具\n", "\n", "让我们首先定义我们将用于示例的工具和模型。正如在 [ReAct 代理指南](../../how-tos/react-agent-from-scratch-function) 中一样，我们将使用一个占位符工具来获取某个位置的天气描述。\n", "\n", "在本示例中，我们将使用 [OpenAI](https://js.langchain.com/docs/integrations/providers/openai/) 聊天模型，但任何[支持工具调用](https://js.langchain.com/docs/integrations/chat/) 的模型就足够了。"]}, {"cell_type": "code", "execution_count": 5, "metadata": {}, "outputs": [], "source": ["import { ChatOpenAI } from \"@langchain/openai\";\n", "import { tool } from \"@langchain/core/tools\";\n", "import { z } from \"zod\";\n", "\n", "const model = new ChatOpenAI({\n", "  model: \"gpt-4o-mini\",\n", "});\n", "\n", "const getWeather = tool(async ({ location }) => {\n", "  // 这是实际实现的占位符\n", "  const lowercaseLocation = location.toLowerCase();\n", "  if (lowercaseLocation.includes(\"sf\") || lowercaseLocation.includes(\"san francisco\")) {\n", "    return \"It's sunny!\";\n", "  } else if (lowercaseLocation.includes(\"boston\")) {\n", "    return \"It's rainy!\";\n", "  } else {\n", "    return `I am not sure what the weather is in ${location}`;\n", "  }\n", "}, {\n", "  name: \"getWeather\",\n", "  schema: z.object({\n", "    location: z.string().describe(\"Location to get the weather for\"),\n", "  }),\n", "  description: \"Call to get the weather from a specific location.\",\n", "});"]}, {"cell_type": "markdown", "metadata": {}, "source": ["要向人类寻求帮助，我们可以简单地添加一个调用 [interrupt](../../concepts/ human_in_the_loop/#interrupt) 的工具："]}, {"cell_type": "code", "execution_count": 6, "metadata": {}, "outputs": [], "source": ["import { interrupt } from \"@langchain/langgraph\";\n", "import { z } from \"zod\";\n", "\n", "const humanAssistance = tool(async ({ query }) => {\n", "  const humanResponse = interrupt({ query });\n", "  return humanResponse.data;\n", "}, {\n", "  name: \"humanAssistance\",\n", "  description: \"Request assistance from a human.\",\n", "  schema: z.object({\n", "    query: z.string().describe(\"Human readable question for the human\")\n", "  })\n", "});\n", "\n", "const tools = [getWeather, humanAssistance];"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### 定义任务\n", "\n", "我们的任务在其他方面与 [ReAct 代理指南](../../how-tos/react-agent-from-scratch-function) 没有变化：\n", "\n", "1. **调用模型**：我们想要使用消息列表查询我们的聊天模型。\n", "2. **调用工具**：如果我们的模型生成工具调用，我们想要执行它们。\n", "\n", "我们只是多了一种可供模型使用的工具。"]}, {"cell_type": "code", "execution_count": 7, "metadata": {}, "outputs": [], "source": ["import {\n", "  type BaseMessageLike,\n", "  AIMessage,\n", "  ToolMessage,\n", "} from \"@langchain/core/messages\";\n", "import { type ToolCall } from \"@langchain/core/messages/tool\";\n", "import { task } from \"@langchain/langgraph\";\n", "\n", "const toolsByName = Object.fromEntries(tools.map((tool) => [tool.name, tool]));\n", "\n", "const callModel = task(\"callModel\", async (messages: BaseMessageLike[]) => {\n", "  const response = await model.bindTools(tools).invoke(messages);\n", "  return response;\n", "});\n", "\n", "const callTool = task(\n", "  \"callTool\",\n", "  async (toolCall: ToolCall): Promise<AIMessage> => {\n", "    const tool = toolsByName[toolCall.name];\n", "    const observation = await tool.invoke(toolCall.args);\n", "    return new ToolMessage({ content: observation, tool_call_id: toolCall.id });\n", "    // 也可以直接将toolCall传递到工具中以返回ToolMessage\n", "    // 返回 tool.invoke(toolCall);\n", "  });"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### 定义入口点\n", "\n", "我们的[入口点](../../concepts/function_api/#entrypoint) 也与 [ReAct 代理指南](../../how-tos/react-agent-from-scratch-function) 保持不变："]}, {"cell_type": "code", "execution_count": 8, "metadata": {}, "outputs": [], "source": ["import { entrypoint, addMessages, MemorySaver } from \"@langchain/langgraph\";\n", "\n", "const agent = entrypoint({\n", "  name: \"agent\",\n", "  checkpointer: new MemorySaver(),\n", "}, async (messages: BaseMessageLike[]) => {\n", "  let currentMessages = messages;\n", "  let llmResponse = await callModel(currentMessages);\n", "  while (true) {\n", "    if (!llmResponse.tool_calls?.length) {\n", "      break;\n", "    }\n", "\n", "    // 执行工具\n", "    const toolResults = await Promise.all(\n", "      llmResponse.tool_calls.map((toolCall) => {\n", "        return callTool(toolCall);\n", "      })\n", "    );\n", "    \n", "    // 附加到消息列表\n", "    currentMessages = addMessages(currentMessages, [llmResponse, ...toolResults]);\n", "\n", "    // 再次调用模型\n", "    llmResponse = await callModel(currentMessages);\n", "  }\n", "\n", "  return llmResponse;\n", "});"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### 用法\n", "\n", "让我们用一个需要人工帮助的问题来调用我们的模型。我们的问题还需要调用 `getWeather` 工具："]}, {"cell_type": "code", "execution_count": 9, "metadata": {}, "outputs": [], "source": ["import { BaseMessage, isAIMessage } from \"@langchain/core/messages\";\n", "\n", "const prettyPrintMessage = (message: BaseMessage) => {\n", "  console.log(\"=\".repeat(30), `${message.getType()} message`, \"=\".repeat(30));\n", "  console.log(message.content);\n", "  if (isAIMessage(message) && message.tool_calls?.length) {\n", "    console.log(JSON.stringify(message.tool_calls, null, 2));\n", "  }\n", "}\n", "\n", "const prettyPrintStep = (step: Record<string, any>) => {\n", "  if (step.__metadata__?.cached) {\n", "    return;\n", "  }\n", "  for (const [taskName, update] of Object.entries(step)) {\n", "    const message = update as BaseMessage;\n", "    // 仅打印任务更新\n", "    if (taskName === \"agent\") continue;\n", "    console.log(`\\n${taskName}:`);\n", "    if (taskName === \"__interrupt__\") {\n", "      console.log(update);\n", "    } else {\n", "      prettyPrintMessage(message);\n", "    }\n", "  }\n", "}"]}, {"cell_type": "code", "execution_count": 11, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["{\n", "  role: 'user',\n", "  content: 'Can you reach out for human assistance: what should I feed my cat? Separately, can you check the weather in San Francisco?'\n", "}\n", "\n", "callModel:\n", "============================== ai message ==============================\n", "\n", "[\n", "  {\n", "    \"name\": \"humanAssistance\",\n", "    \"args\": {\n", "      \"query\": \"What should I feed my cat?\"\n", "    },\n", "    \"type\": \"tool_call\",\n", "    \"id\": \"call_TwrNq6tGI61cDCJEpj175h7J\"\n", "  },\n", "  {\n", "    \"name\": \"getWeather\",\n", "    \"args\": {\n", "      \"location\": \"San Francisco\"\n", "    },\n", "    \"type\": \"tool_call\",\n", "    \"id\": \"call_fMzUBvc0SpZpXxM2LQLXfbke\"\n", "  }\n", "]\n", "\n", "callTool:\n", "============================== tool message ==============================\n", "It's sunny!\n", "\n", "__interrupt__:\n", "[\n", "  {\n", "    value: { query: 'What should I feed my cat?' },\n", "    when: 'during',\n", "    resumable: true,\n", "    ns: [ 'callTool:2e0c6c40-9541-57ef-a7af-24213a10d5a4' ]\n", "  }\n", "]\n"]}], "source": ["const userMessage = {\n", "  role: \"user\",\n", "  content: [\n", "    \"Can you reach out for human assistance: what should I feed my cat?\",\n", "    \"Separately, can you check the weather in San Francisco?\"\n", "  ].join(\" \"),\n", "};\n", "console.log(userMessage);\n", "\n", "const agentStream = await agent.stream([userMessage], {\n", "  configurable: {\n", "    thread_id: \"1\",\n", "  }\n", "});\n", "\n", "let lastStep;\n", "\n", "for await (const step of agentStream) {\n", "  prettyPrintStep(step);\n", "  lastStep = step;\n", "}"]}, {"cell_type": "markdown", "metadata": {}, "source": ["请注意，我们生成了两个工具调用，尽管我们的运行被中断，但我们并没有阻止 `get_weather` 工具的执行。\n", "\n", "让我们检查一下被中断的地方："]}, {"cell_type": "code", "execution_count": 12, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["{\"__interrupt__\":[{\"value\":{\"query\":\"What should I feed my cat?\"},\"when\":\"during\",\"resumable\":true,\"ns\":[\"callTool:2e0c6c40-9541-57ef-a7af-24213a10d5a4\"]}]}\n"]}], "source": ["console.log(JSON.stringify(lastStep));"]}, {"cell_type": "markdown", "metadata": {}, "source": ["我们可以通过发出[命令](../../concepts/ human_in_the_loop/#the-command-primitive)来恢复执行。请注意，我们在 `Command` 中提供的数据可以根据 `humanAssistance` 的实现根据您的需求进行定制。"]}, {"cell_type": "code", "execution_count": 13, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["\n", "callTool:\n", "============================== tool message ==============================\n", "You should feed your cat a fish.\n", "\n", "callModel:\n", "============================== ai message ==============================\n", "For your cat, it is suggested that you feed it fish. As for the weather in San Francisco, it's currently sunny!\n"]}], "source": ["import { Command } from \"@langchain/langgraph\";\n", "\n", "const humanResponse = \"You should feed your cat a fish.\";\n", "const humanCommand = new Command({\n", "  resume: { data: humanResponse },\n", "});\n", "\n", "const resumeStream2 = await agent.stream(humanCommand, config);\n", "\n", "for await (const step of resumeStream2) {\n", "  prettyPrintStep(step);\n", "}"]}, {"cell_type": "markdown", "metadata": {}, "source": ["上面，当我们恢复时，我们提供最终的工具消息，允许模型生成其响应。查看 LangSmith 跟踪以查看运行的完整细分：\n", "\n", "1. [初始查询追踪](https://smith.langchain.com/public/c007b042-fdd3-49e7-acbe-cadf6969de4b/r)\n", "2.【恢复后追踪】(https://smith.langchain.com/public/1cea310a-13f5-4de9-ae1c-045b8b33015e/r)\n", "\n", "**注意：** `interrupt` 函数通过抛出特殊的 `GraphInterrupt` 错误来传播。因此，您应该避免在 `interrupt` 函数周围使用 `try/catch` 块 - 或者如果这样做，请确保在 `catch` 块中再次引发 `GraphInterrupt` 错误。"]}], "metadata": {"kernelspec": {"display_name": "TypeScript", "language": "typescript", "name": "tslab"}, "language_info": {"codemirror_mode": {"mode": "typescript", "name": "javascript", "typescript": true}, "file_extension": ".ts", "mimetype": "text/typescript", "name": "typescript", "version": "3.7.2"}}, "nbformat": 4, "nbformat_minor": 4}