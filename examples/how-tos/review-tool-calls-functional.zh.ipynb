{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# 如何查看工具调用（函数式API）\n", "\n", "!!!信息“先决条件”\n", "本指南假设您熟悉以下内容：\n", "\n", "- 使用[中断](../../concepts/ human_in_the_loop/#interrupt) 实施[人机循环](../../concepts/ human_in_the_loop) 工作流程\n", "- [如何使用功能 API 创建 ReAct 代理](../../how-tos/react-agent-from-scratch-function)\n", "\n", "本指南演示如何使用 LangGraph [Functional API](../../concepts/featured_api) 在 ReAct 代理中实现人机交互工作流程。\n", "\n", "我们将基于[如何使用功能 API 创建 ReAct 代理](../../how-tos/react-agent-from-scratch-function) 指南中创建的代理进行构建。\n", "\n", "具体来说，我们将演示如何在执行之前检查[聊天模型](https://js.langchain.com/docs/concepts/chat_models/)生成的[工具调用](https://js.langchain.com/docs/concepts/tool_calling/)。这可以通过在应用程序的关键点使用 [interrupt](../../concepts/ human_in_the_loop/#interrupt) 函数来完成。\n", "\n", "**预览**：\n", "\n", "我们将实现一个简单的函数，用于检查从聊天模型生成的工具调用，并从应用程序的 [entrypoint](../../concepts/function_api/#entrypoint) 内部调用它：\n", "```ts\n", "function reviewToolCall(toolCall: ToolCall): ToolCall | ToolMessage {\n", "  // Interrupt for human review\n", "  const humanReview = interrupt({\n", "    question: \"Is this correct?\",\n", "    tool_call: toolCall,\n", "  });\n", "\n", "  const { action, data } = humanReview;\n", "\n", "  if (action === \"continue\") {\n", "    return toolCall;\n", "  } else if (action === \"update\") {\n", "    return {\n", "      ...toolCall,\n", "      args: data,\n", "    };\n", "  } else if (action === \"feedback\") {\n", "    return new ToolMessage({\n", "      content: data,\n", "      name: toolCall.name,\n", "      tool_call_id: toolCall.id,\n", "    });\n", "  }\n", "  throw new Error(`Unsupported review action: ${action}`);\n", "}\n", "```"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 设置\n", "\n", "!!!注意兼容性\n", "\n", "本指南需要 `@langchain/langgraph>=0.2.42`。\n", "\n", "首先，安装本示例所需的依赖项：\n", "```bash\n", "npm install @langchain/langgraph @langchain/openai @langchain/core zod\n", "```\n", "接下来，我们需要为 OpenAI 设置 API 密钥（我们将使用的 LLM）：\n", "```typescript\n", "process.env.OPENAI_API_KEY = \"YOUR_API_KEY\";\n", "```\n", "!!!提示“为 LangGraph 开发设置 [LangSmith](https://smith.langchain.com)”\n", "\n", "注册 LangSmith 以快速发现问题并提高 LangGraph 项目的性能。LangSmith 允许您使用跟踪数据来调试、测试和监控使用 LangGraph 构建的 LLM 应用程序 — 在[此处](https://docs.smith.langchain.com)了解有关如何开始的更多信息"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 定义模型和工具\n", "\n", "让我们首先定义我们将用于示例的工具和模型。正如在 [ReAct 代理指南](../../how-tos/react-agent-from-scratch-function) 中一样，我们将使用一个占位符工具来获取某个位置的天气描述。\n", "\n", "在本示例中，我们将使用 [OpenAI](https://js.langchain.com/docs/integrations/providers/openai/) 聊天模型，但任何[支持工具调用](https://js.langchain.com/docs/integrations/chat/) 的模型就足够了。"]}, {"cell_type": "code", "execution_count": 1, "metadata": {}, "outputs": [], "source": ["import { ChatOpenAI } from \"@langchain/openai\";\n", "import { tool } from \"@langchain/core/tools\";\n", "import { z } from \"zod\";\n", "\n", "const model = new ChatOpenAI({\n", "  model: \"gpt-4o-mini\",\n", "});\n", "\n", "const getWeather = tool(async ({ location }) => {\n", "  // 这是实际实现的占位符\n", "  const lowercaseLocation = location.toLowerCase();\n", "  if (lowercaseLocation.includes(\"sf\") || lowercaseLocation.includes(\"san francisco\")) {\n", "    return \"It's sunny!\";\n", "  } else if (lowercaseLocation.includes(\"boston\")) {\n", "    return \"It's rainy!\";\n", "  } else {\n", "    return `I am not sure what the weather is in ${location}`;\n", "  }\n", "}, {\n", "  name: \"getWeather\",\n", "  schema: z.object({\n", "    location: z.string().describe(\"Location to get the weather for\"),\n", "  }),\n", "  description: \"Call to get the weather from a specific location.\",\n", "});\n", "\n", "const tools = [getWeather];"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 定义任务\n", "\n", "我们的[任务](../../concepts/function_api/#task)与[ReAct代理指南](../../how-tos/react-agent-from-scratch-function)保持不变：\n", "\n", "1. **调用模型**：我们想要使用消息列表查询我们的聊天模型。\n", "2. **调用工具**：如果我们的模型生成工具调用，我们想要执行它们。"]}, {"cell_type": "code", "execution_count": 2, "metadata": {}, "outputs": [], "source": ["import {\n", "  type BaseMessageLike,\n", "  AIMessage,\n", "  ToolMessage,\n", "} from \"@langchain/core/messages\";\n", "import { type ToolCall } from \"@langchain/core/messages/tool\";\n", "import { task } from \"@langchain/langgraph\";\n", "\n", "const toolsByName = Object.fromEntries(tools.map((tool) => [tool.name, tool]));\n", "\n", "const callModel = task(\"callModel\", async (messages: BaseMessageLike[]) => {\n", "  const response = await model.bindTools(tools).invoke(messages);\n", "  return response;\n", "});\n", "\n", "const callTool = task(\n", "  \"callTool\",\n", "  async (toolCall: ToolCall): Promise<AIMessage> => {\n", "    const tool = toolsByName[toolCall.name];\n", "    const observation = await tool.invoke(toolCall.args);\n", "    return new ToolMessage({ content: observation, tool_call_id: toolCall.id });\n", "    // 也可以直接将toolCall传递到工具中以返回ToolMessage\n", "    // 返回 tool.invoke(toolCall);\n", "  });"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 定义入口点\n", "\n", "为了在执行前检查工具调用，我们添加了一个调用 [interrupt](../../concepts/ human_in_the_loop/#interrupt) 的 `reviewToolCalls` 函数。当调用此函数时，执行将暂停，直到我们发出命令来恢复它。\n", "\n", "给定一个工具调用，我们的函数将 `interrupt` 进行人工审查。那时我们可以：\n", "\n", "- 接受工具调用；\n", "- 修改工具调用并继续；\n", "- 生成自定义工具消息（例如，指示模型重新格式化其工具调用）。\n", "\n", "我们将在下面的[使用示例](#usage)中演示这三种情况。"]}, {"cell_type": "code", "execution_count": 3, "metadata": {}, "outputs": [], "source": ["import { interrupt } from \"@langchain/langgraph\";\n", "\n", "function reviewToolCall(toolCall: ToolCall): ToolCall | ToolMessage {\n", "  // 中断人工审核\n", "  const humanReview = interrupt({\n", "    question: \"Is this correct?\",\n", "    tool_call: toolCall,\n", "  });\n", "\n", "  const { action, data } = humanReview;\n", "\n", "  if (action === \"continue\") {\n", "    return toolCall;\n", "  } else if (action === \"update\") {\n", "    return {\n", "      ...toolCall,\n", "      args: data,\n", "    };\n", "  } else if (action === \"feedback\") {\n", "    return new ToolMessage({\n", "      content: data,\n", "      name: toolCall.name,\n", "      tool_call_id: toolCall.id,\n", "    });\n", "  }\n", "  throw new Error(`Unsupported review action: ${action}`);\n", "}"]}, {"cell_type": "markdown", "metadata": {}, "source": ["我们现在可以更新我们的 [entrypoint](../../concepts/tical_api/#entrypoint) 以查看生成的工具调用。如果工具调用被接受或修改，我们将以与以前相同的方式执行。否则，我们只需附加人类提供的 `ToolMessage`。\n", "\n", "!!!提示\n", "\n", "先前任务的结果（在本例中为初始模型调用）将被保留，以便它们不会在 `interrupt` 之后再次运行。"]}, {"cell_type": "code", "execution_count": 4, "metadata": {}, "outputs": [], "source": ["import {\n", "  MemorySaver,\n", "  addMessages,\n", "  entrypoint,\n", "  getPreviousState,\n", "} from \"@langchain/langgraph\";\n", "\n", "const checkpointer = new MemorySaver();\n", "\n", "const agent = entrypoint({\n", "  checkpointer,\n", "  name: \"agent\",\n", "}, async (messages: BaseMessageLike[]) => {\n", "  const previous = getPreviousState<BaseMessageLike[]>() ?? [];\n", "  let currentMessages = addMessages(previous, messages);\n", "  let llmResponse = await callModel(currentMessages);\n", "  while (true) {\n", "    if (!llmResponse.tool_calls?.length) {\n", "      break;\n", "    }\n", "    // 检查工具调用\n", "    const toolResults: ToolMessage[] = [];\n", "    const toolCalls: ToolCall[] = [];\n", "    \n", "    for (let i = 0; i < llmResponse.tool_calls.length; i++) {\n", "      const review = await reviewToolCall(llmResponse.tool_calls[i]);\n", "      if (review instanceof ToolMessage) {\n", "        toolResults.push(review);\n", "      } else { // is a validated tool call\n", "        toolCalls.push(review);\n", "        if (review !== llmResponse.tool_calls[i]) {\n", "          llmResponse.tool_calls[i] = review;\n", "        }\n", "      }\n", "    }\n", "    // 执行剩余的工具调用\n", "    const remainingToolResults = await Promise.all(\n", "      toolCalls.map((toolCall) => callTool(toolCall))\n", "    );\n", "    \n", "    // 附加到消息列表\n", "    currentMessages = addMessages(\n", "      currentMessages,\n", "      [llmResponse, ...toolResults, ...remainingToolResults]\n", "    );\n", "\n", "    // 再次调用模型\n", "    llmResponse = await callModel(currentMessages);\n", "  }\n", "  // 生成最终响应\n", "  currentMessages = addMessages(currentMessages, llmResponse);\n", "  return entrypoint.final({\n", "    value: llmResponse,\n", "    save: currentMessages\n", "  });\n", "});"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### 用法\n", "\n", "让我们演示一些场景。"]}, {"cell_type": "code", "execution_count": 5, "metadata": {}, "outputs": [], "source": ["import { BaseMessage, isAIMessage } from \"@langchain/core/messages\";\n", "\n", "const prettyPrintMessage = (message: BaseMessage) => {\n", "  console.log(\"=\".repeat(30), `${message.getType()} message`, \"=\".repeat(30));\n", "  console.log(message.content);\n", "  if (isAIMessage(message) && message.tool_calls?.length) {\n", "    console.log(JSON.stringify(message.tool_calls, null, 2));\n", "  }\n", "}\n", "\n", "const printStep = (step: Record<string, any>) => {\n", "  if (step.__metadata__?.cached) {\n", "    return;\n", "  }\n", "  for (const [taskName, result] of Object.entries(step)) {\n", "    if (taskName === \"agent\") {\n", "      continue; // just stream from tasks\n", "    }\n", "    \n", "    console.log(`\\n${taskName}:`);\n", "    if (taskName === \"__interrupt__\" || taskName === \"reviewToolCall\") {\n", "      console.log(JSON.stringify(result, null, 2));\n", "    } else {\n", "      prettyPrintMessage(result);\n", "    }\n", "  }\n", "};"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### 接受工具调用\n", "\n", "要接受工具调用，我们只需在 `Command` 中提供的数据中指示工具调用应该通过。"]}, {"cell_type": "code", "execution_count": 6, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["{ role: 'user', content: \"What's the weather in san francisco?\" }\n"]}, {"name": "stdout", "output_type": "stream", "text": ["\n", "callModel:\n", "============================== ai message ==============================\n", "\n", "[\n", "  {\n", "    \"name\": \"getWeather\",\n", "    \"args\": {\n", "      \"location\": \"San Francisco\"\n", "    },\n", "    \"type\": \"tool_call\",\n", "    \"id\": \"call_pe7ee3A4lOO4Llr2NcfRukyp\"\n", "  }\n", "]\n", "\n", "__interrupt__:\n", "[\n", "  {\n", "    \"value\": {\n", "      \"question\": \"Is this correct?\",\n", "      \"tool_call\": {\n", "        \"name\": \"getWeather\",\n", "        \"args\": {\n", "          \"location\": \"San Francisco\"\n", "        },\n", "        \"type\": \"tool_call\",\n", "        \"id\": \"call_pe7ee3A4lOO4Llr2NcfRukyp\"\n", "      }\n", "    },\n", "    \"when\": \"during\",\n", "    \"resumable\": true,\n", "    \"ns\": [\n", "      \"agent:dcee519a-80f5-5950-9e1c-e8bb85ed436f\"\n", "    ]\n", "  }\n", "]\n"]}], "source": ["const config = {\n", "  configurable: {\n", "    thread_id: \"1\"\n", "  }\n", "};\n", "\n", "const userMessage = {\n", "  role: \"user\",\n", "  content: \"What's the weather in san francisco?\"\n", "};\n", "console.log(userMessage);\n", "\n", "const stream = await agent.stream([userMessage], config);\n", "\n", "for await (const step of stream) {\n", "  printStep(step);\n", "}"]}, {"cell_type": "code", "execution_count": 7, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["\n", "callTool:\n", "============================== tool message ==============================\n", "It's sunny!\n", "\n", "callModel:\n", "============================== ai message ==============================\n", "The weather in San Francisco is sunny!\n"]}], "source": ["import { Command } from \"@langchain/langgraph\";\n", "\n", "// 突出显示下一行\n", "const humanInput = new Command({\n", "  // 突出显示下一行\n", "  resume: {\n", "    // 突出显示下一行\n", "    action: \"continue\",\n", "    // 突出显示下一行\n", "  },\n", "  // 突出显示下一行\n", "});\n", "\n", "const resumedStream = await agent.stream(humanInput, config)\n", "\n", "for await (const step of resumedStream) {\n", "  printStep(step);\n", "}"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### 修改工具调用\n", "\n", "要修改工具调用，我们可以提供更新的参数。"]}, {"cell_type": "code", "execution_count": 8, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["{ role: 'user', content: \"What's the weather in san francisco?\" }\n", "\n", "callModel:\n", "============================== ai message ==============================\n", "\n", "[\n", "  {\n", "    \"name\": \"getWeather\",\n", "    \"args\": {\n", "      \"location\": \"San Francisco\"\n", "    },\n", "    \"type\": \"tool_call\",\n", "    \"id\": \"call_JEOqaUEvYJ4pzMtVyCQa6H2H\"\n", "  }\n", "]\n", "\n", "__interrupt__:\n", "[\n", "  {\n", "    \"value\": {\n", "      \"question\": \"Is this correct?\",\n", "      \"tool_call\": {\n", "        \"name\": \"getWeather\",\n", "        \"args\": {\n", "          \"location\": \"San Francisco\"\n", "        },\n", "        \"type\": \"tool_call\",\n", "        \"id\": \"call_JEOqaUEvYJ4pzMtVyCQa6H2H\"\n", "      }\n", "    },\n", "    \"when\": \"during\",\n", "    \"resumable\": true,\n", "    \"ns\": [\n", "      \"agent:d5c54c67-483a-589a-a1e7-2a8465b3ef13\"\n", "    ]\n", "  }\n", "]\n"]}], "source": ["const config2 = {\n", "  configurable: {\n", "    thread_id: \"2\"\n", "  }\n", "};\n", "\n", "const userMessage2 = {\n", "  role: \"user\",\n", "  content: \"What's the weather in san francisco?\"\n", "};\n", "\n", "console.log(userMessage2);\n", "\n", "const stream2 = await agent.stream([userMessage2], config2);\n", "\n", "for await (const step of stream2) {\n", "  printStep(step);\n", "}"]}, {"cell_type": "code", "execution_count": 9, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["\n", "callTool:\n", "============================== tool message ==============================\n", "It's sunny!\n", "\n", "callModel:\n", "============================== ai message ==============================\n", "The weather in San Francisco is sunny!\n"]}], "source": ["// 突出显示下一行\n", "const humanInput2 = new Command({\n", "  // 突出显示下一行\n", "  resume: {\n", "    // 突出显示下一行\n", "    action: \"update\",\n", "    // 突出显示下一行\n", "    data: { location: \"SF, CA\" },\n", "    // 突出显示下一行\n", "  },\n", "  // 突出显示下一行\n", "});\n", "\n", "const resumedStream2 = await agent.stream(humanInput2, config2)\n", "\n", "for await (const step of resumedStream2) {\n", "  printStep(step);\n", "}"]}, {"cell_type": "markdown", "metadata": {}, "source": ["这次运行的 LangSmith 跟踪信息特别丰富：\n", "\n", "- 在[中断之前](https://smith.langchain.com/public/abf80a16-3e15-484b-bbbb-23017593bd39/r)中，我们生成位置`\"San Francisco\"`的工具调用。\n", "- 在[恢复后](https://smith.langchain.com/public/233a7e32-a43e-4939-9c04-96fd4254ce65/r)的跟踪中，我们看到消息中的工具调用已更新为`\"SF, CA\"`。"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### 生成自定义 ToolMessage\n", "\n", "为了生成自定义 `ToolMessage`，我们提供消息的内容。在这种情况下，我们将要求模型重新格式化其工具调用。"]}, {"cell_type": "code", "execution_count": 10, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["{ role: 'user', content: \"What's the weather in san francisco?\" }\n", "\n", "callModel:\n", "============================== ai message ==============================\n", "\n", "[\n", "  {\n", "    \"name\": \"getWeather\",\n", "    \"args\": {\n", "      \"location\": \"San Francisco\"\n", "    },\n", "    \"type\": \"tool_call\",\n", "    \"id\": \"call_HNRjJLJo4U78dtk0uJ9YZF6V\"\n", "  }\n", "]\n", "\n", "__interrupt__:\n", "[\n", "  {\n", "    \"value\": {\n", "      \"question\": \"Is this correct?\",\n", "      \"tool_call\": {\n", "        \"name\": \"getWeather\",\n", "        \"args\": {\n", "          \"location\": \"San Francisco\"\n", "        },\n", "        \"type\": \"tool_call\",\n", "        \"id\": \"call_HNRjJLJo4U78dtk0uJ9YZF6V\"\n", "      }\n", "    },\n", "    \"when\": \"during\",\n", "    \"resumable\": true,\n", "    \"ns\": [\n", "      \"agent:6f313de8-c19e-5c3e-bdff-f90cdd68d0de\"\n", "    ]\n", "  }\n", "]\n"]}], "source": ["const config3 = {\n", "  configurable: {\n", "    thread_id: \"3\"\n", "  }\n", "};\n", "\n", "const userMessage3 = {\n", "  role: \"user\",\n", "  content: \"What's the weather in san francisco?\"\n", "};\n", "\n", "console.log(userMessage3);\n", "\n", "const stream3 = await agent.stream([userMessage3], config3);\n", "\n", "for await (const step of stream3) {\n", "  printStep(step);\n", "}"]}, {"cell_type": "code", "execution_count": 11, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["\n", "callModel:\n", "============================== ai message ==============================\n", "\n", "[\n", "  {\n", "    \"name\": \"getWeather\",\n", "    \"args\": {\n", "      \"location\": \"San Francisco, CA\"\n", "    },\n", "    \"type\": \"tool_call\",\n", "    \"id\": \"call_5V4Oj4JV2DVfeteM4Aaf2ieD\"\n", "  }\n", "]\n", "\n", "__interrupt__:\n", "[\n", "  {\n", "    \"value\": {\n", "      \"question\": \"Is this correct?\",\n", "      \"tool_call\": {\n", "        \"name\": \"getWeather\",\n", "        \"args\": {\n", "          \"location\": \"San Francisco, CA\"\n", "        },\n", "        \"type\": \"tool_call\",\n", "        \"id\": \"call_5V4Oj4JV2DVfeteM4Aaf2ieD\"\n", "      }\n", "    },\n", "    \"when\": \"during\",\n", "    \"resumable\": true,\n", "    \"ns\": [\n", "      \"agent:6f313de8-c19e-5c3e-bdff-f90cdd68d0de\"\n", "    ]\n", "  }\n", "]\n"]}], "source": ["// 突出显示下一行\n", "const humanInput3 = new Command({\n", "  // 突出显示下一行\n", "  resume: {\n", "    // 突出显示下一行\n", "    action: \"feedback\",\n", "    // 突出显示下一行\n", "    data: \"Please format as <City>, <State>.\",\n", "    // 突出显示下一行\n", "  },\n", "  // 突出显示下一行\n", "});\n", "\n", "const resumedStream3 = await agent.stream(humanInput3, config3)\n", "\n", "for await (const step of resumedStream3) {\n", "  printStep(step);\n", "}"]}, {"cell_type": "markdown", "metadata": {}, "source": ["重新格式化后，我们就可以接受它："]}, {"cell_type": "code", "execution_count": 12, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["\n", "callTool:\n", "============================== tool message ==============================\n", "It's sunny!\n", "\n", "callModel:\n", "============================== ai message ==============================\n", "The weather in San Francisco, CA is sunny!\n"]}], "source": ["// 突出显示下一行\n", "const continueCommand = new Command({\n", "  // 突出显示下一行\n", "  resume: {\n", "    // 突出显示下一行\n", "    action: \"continue\",\n", "    // 突出显示下一行\n", "  },\n", "  // 突出显示下一行\n", "});\n", "\n", "const continueStream = await agent.stream(continueCommand, config3)\n", "\n", "for await (const step of continueStream) {\n", "  printStep(step);\n", "}"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}], "metadata": {"kernelspec": {"display_name": "TypeScript", "language": "typescript", "name": "tslab"}, "language_info": {"codemirror_mode": {"mode": "typescript", "name": "javascript", "typescript": true}, "file_extension": ".ts", "mimetype": "text/typescript", "name": "typescript", "version": "3.7.2"}}, "nbformat": 4, "nbformat_minor": 4}