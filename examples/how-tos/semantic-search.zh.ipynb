{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# 如何将语义搜索添加到代理的内存中\n", "\n", "本指南介绍如何在代理的内存存储中启用语义搜索。这使您的代理可以通过语义相似性在长期记忆存储中搜索项目。\n", "\n", "## 依赖关系和环境设置\n", "\n", "首先，安装本指南所需的依赖项。\n", "```bash\n", "npm install \\\n", "  @langchain/langgraph \\\n", "  @langchain/openai \\\n", "  @langchain/core \\\n", "  uuid \\\n", "  zod\n", "```\n", "接下来，我们需要为 OpenAI 设置 API 密钥（我们将使用的 LLM）\n", "```bash\n", "export OPENAI_API_KEY=your-api-key\n", "```\n", "或者，我们可以为 [LangSmith 追踪](https://smith.langchain.com/) 设置 API 密钥，这将为我们提供一流的可观察性。\n", "```bash\n", "export LANGCHAIN_TRACING_V2=\"true\"\n", "export LANGCHAIN_CALLBACKS_BACKGROUND=\"true\"\n", "export LANGCHAIN_API_KEY=your-api-key\n", "```"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 使用语义搜索初始化内存存储\n", "\n", "在这里，我们使用[索引配置](https://langchain-ai.github.io/langgraphjs/reference/interfaces/checkpoint.IndexConfig.html)创建内存存储。\n", "\n", "默认情况下，商店配置为没有语义/向量搜索。您可以在创建商店时通过向商店的构造函数提供 [IndexConfig](https://langchain-ai.github.io/langgraphjs/reference/interfaces/checkpoint.IndexConfig.html) 来选择对项目建立索引。\n", "\n", "如果您的存储类没有实现此接口，或者您没有传入索引配置，则语义搜索将被禁用，并且传递给 `put` 的所有 `index` 参数将无效。\n", "\n", "现在，让我们创建该商店！"]}, {"cell_type": "code", "execution_count": 1, "metadata": {}, "outputs": [], "source": ["import { OpenAIEmbeddings } from \"@langchain/openai\";\n", "import { InMemoryStore } from \"@langchain/langgraph\";\n", "\n", "const embeddings = new OpenAIEmbeddings({\n", "  model: \"text-embedding-3-small\",\n", "});\n", "\n", "const store = new InMemoryStore({\n", "  index: {\n", "    embeddings,\n", "    dims: 1536,\n", "  }\n", "});"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 内存的解剖\n", "\n", "在我们进入语义搜索之前，让我们先看看记忆是如何构造的，以及如何存储它们："]}, {"cell_type": "code", "execution_count": 2, "metadata": {}, "outputs": [], "source": ["let namespace = [\"user_123\", \"memories\"]\n", "let memoryKey = \"favorite_food\"\n", "let memoryValue = {\"text\": \"I love pizza\"}\n", "\n", "await store.put(namespace, memoryKey, memoryValue)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["如您所见，内存由名称空间、键和值组成。\n", "\n", "**命名空间**是多维值（字符串数组），允许您根据应用程序的需要对内存进行分段。在本例中，我们使用用户 ID (`\"user_123\"`) 作为命名空间数组的第一个维度，按用户对内存进行分段。\n", "\n", "**键**是标识命名空间内的内存的任意字符串。如果多次写入同一命名空间中的同一键，则会覆盖存储在该键下的内存。\n", "\n", "**值**是代表实际存储的内存的对象。这些可以是任何对象，只要它是可序列化的。您可以根据应用程序的需要构建这些对象。\n", "\n", "## 简单的内存检索\n", "\n", "让我们向我们的存储添加更多内存，然后通过它的键获取其中一个内存以检查它是否正确存储。"]}, {"cell_type": "code", "execution_count": 3, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["I am a tunnel engineer\n"]}], "source": ["await store.put(\n", "  [\"user_123\", \"memories\"],\n", "  \"italian_food\",\n", "  {\"text\": \"I prefer Italian food\"}\n", ")\n", "await store.put(\n", "  [\"user_123\", \"memories\"],\n", "  \"spicy_food\",\n", "  {\"text\": \"I don't like spicy food\"}\n", ")\n", "await store.put(\n", "  [\"user_123\", \"memories\"],\n", "  \"occupation\",\n", "  {\"text\": \"I am an airline pilot\"}\n", ")\n", "\n", "// 这个职业太崇高了，我们重写吧\n", "// 还有更多……脚踏实地\n", "await store.put(\n", "  [\"user_123\", \"memories\"],\n", "  \"occupation\",\n", "  {\"text\": \"I am a tunnel engineer\"}\n", ")\n", "\n", "// 现在让我们检查一下我们的占用内存是否被覆盖了\n", "const occupation = await store.get([\"user_123\", \"memories\"], \"occupation\")\n", "console.log(occupation.value.text)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 用自然语言搜索记忆\n", "\n", "现在我们已经了解了如何通过命名空间和键来存储和检索记忆，让我们看看如何使用语义搜索来检索记忆。\n", "\n", "想象一下，我们有一大堆想要搜索的记忆，但我们不知道与我们想要检索的记忆相对应的密钥。语义搜索允许我们通过使用文本嵌入执行自然语言查询来搜索没有键的内存存储。我们在以下示例中演示了这一点："]}, {"cell_type": "code", "execution_count": 4, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Memory: I am a tunnel engineer (similarity: 0.3070681445327329)\n", "Memory: I prefer Italian food (similarity: 0.1435366180543232)\n", "Memory: I love pizza (similarity: 0.10650935500808985)\n"]}], "source": ["const memories = await store.search([\"user_123\", \"memories\"], {\n", "  query: \"What is my occupation?\",\n", "  limit: 3,\n", "});\n", "\n", "for (const memory of memories) {\n", "  console.log(`Memory: ${memory.value.text} (similarity: ${memory.score})`);\n", "}"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 简单示例：ReAct 代理中的长期语义记忆\n", "\n", "让我们看一个为智能体提供长期记忆的简单示例。\n", "\n", "长期记忆可以分为两个阶段：存储和回忆。\n", "\n", "在下面的示例中，我们通过为代理提供一个可用于创建新内存的工具来处理存储。\n", "\n", "为了处理召回，我们将添加一个提示步骤，使用用户聊天消息中的文本查询内存存储。然后，我们将该查询的结果注入到系统消息中。\n", "\n", "### 简单的内存存储工具\n", "\n", "让我们首先创建一个让法学硕士存储新记忆的工具："]}, {"cell_type": "code", "execution_count": 5, "metadata": {}, "outputs": [], "source": ["import { tool } from \"@langchain/core/tools\";\n", "import { LangGraphRunnableConfig } from \"@langchain/langgraph\";\n", "\n", "import { z } from \"zod\";\n", "import { v4 as uuidv4 } from \"uuid\";\n", "\n", "const upsertMemoryTool = tool(async (\n", "  { content },\n", "  config: LangGraphRunnableConfig\n", "): Promise<string> => {\n", "  const store = config.store as InMemoryStore;\n", "  if (!store) {\n", "    throw new Error(\"No store provided to tool.\");\n", "  }\n", "  await store.put(\n", "    [\"user_123\", \"memories\"],\n", "    uuidv4(), // give each memory its own unique ID\n", "    { text: content }\n", "  );\n", "  return \"Stored memory.\";\n", "}, {\n", "  name: \"upsert_memory\",\n", "  schema: z.object({\n", "    content: z.string().describe(\"The content of the memory to store.\"),\n", "  }),\n", "  description: \"Upsert long-term memories.\",\n", "});"]}, {"cell_type": "markdown", "metadata": {}, "source": ["在上面的工具中，我们使用UUID作为密钥，这样内存存储就可以无限地积累内存，而不用担心密钥冲突。我们这样做而不是将内存累积到单个对象或数组中，因为内存存储按键索引项目。在存储中为每个存储器赋予其自己的密钥允许为每个存储器分配其自己的唯一嵌入向量，该嵌入向量可以与搜索查询相匹配。\n", "\n", "### 简单的语义回忆机制\n", "\n", "现在我们有了一个存储记忆的工具，让我们创建一个提示函数，我们可以将其与 `createReactAgent` 一起使用来处理调用机制。\n", "\n", "请注意，如果我们在这里不使用 `createReactAgent`，您可以使用与图形中的第一个节点相同的函数，并且它也可以正常工作。"]}, {"cell_type": "code", "execution_count": 6, "metadata": {}, "outputs": [], "source": ["import { MessagesAnnotation } from \"@langchain/langgraph\";\n", "\n", "const addMemories = async (\n", "  state: typeof MessagesAnnotation.State,\n", "  config: LangGraphRunnableConfig\n", ") => {\n", "  const store = config.store as InMemoryStore;\n", "\n", "  if (!store) {\n", "    throw new Error(\"No store provided to state modifier.\");\n", "  }\n", "  \n", "  // 根据用户的最后一条消息进行搜索\n", "  const items = await store.search(\n", "    [\"user_123\", \"memories\"], \n", "    { \n", "      // 假设这不是一条复杂的消息\n", "      query: state.messages[state.messages.length - 1].content as string,\n", "      limit: 4 \n", "    }\n", "  );\n", "\n", "  \n", "  const memories = items.length \n", "    ? `## Memories of user\\n${\n", "      items.map(item => `${item.value.text} (similarity: ${item.score})`).join(\"\\n\")\n", "    }`\n", "    : \"\";\n", "\n", "  // 将检索到的记忆添加到系统消息中\n", "  return [\n", "    { role: \"system\", content: `You are a helpful assistant.\\n${memories}` },\n", "    ...state.messages\n", "  ];\n", "};"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### 把它们放在一起\n", "\n", "最后，让我们使用 `createReactAgent` 将它们组合到一个代理中。请注意，我们在这里没有添加检查点。下面的示例不会重用消息历史记录。输入消息中未包含的所有详细信息都将来自上面定义的召回机制。"]}, {"cell_type": "code", "execution_count": 7, "metadata": {}, "outputs": [], "source": ["import { ChatOpenAI } from \"@langchain/openai\";\n", "import { createReactAgent } from \"@langchain/langgraph/prebuilt\";\n", "\n", "const agent = createReactAgent({\n", "  llm: new ChatOpenAI({ model: \"gpt-4o-mini\" }),\n", "  tools: [upsertMemoryTool],\n", "  prompt: addMemories,\n", "  store: store\n", "});"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### 使用我们的样品代理\n", "\n", "现在我们已经把所有东西都放在一起了，让我们测试一下！\n", "\n", "首先，让我们定义一个辅助函数，我们可以用它来打印对话中的消息。"]}, {"cell_type": "code", "execution_count": 8, "metadata": {}, "outputs": [], "source": ["import {\n", "  BaseMessage,\n", "  isSystemMessage,\n", "  isAIMessage,\n", "  isHumanMessage,\n", "  isToolMessage,\n", "  AIMessage,\n", "  HumanMessage,\n", "  ToolMessage,\n", "  SystemMessage,\n", "} from \"@langchain/core/messages\";\n", "\n", "function printMessages(messages: BaseMessage[]) {\n", "  for (const message of messages) {\n", "    if (isSystemMessage(message)) {\n", "      const systemMessage = message as SystemMessage;\n", "      console.log(`System: ${systemMessage.content}`);\n", "    } else if (isHumanMessage(message)) {\n", "      const humanMessage = message as HumanMessage;\n", "      console.log(`User: ${humanMessage.content}`);\n", "    } else if (isAIMessage(message)) {\n", "      const aiMessage = message as AIMessage;\n", "      if (aiMessage.content) {\n", "        console.log(`Assistant: ${aiMessage.content}`);\n", "      }\n", "      if (aiMessage.tool_calls) {\n", "        for (const toolCall of aiMessage.tool_calls) {\n", "          console.log(`\\t${toolCall.name}(${JSON.stringify(toolCall.args)})`);\n", "        }\n", "      }\n", "    } else if (isToolMessage(message)) {\n", "      const toolMessage = message as ToolMessage;\n", "      console.log(\n", "        `\\t\\t${toolMessage.name} -> ${JSON.stringify(toolMessage.content)}`\n", "      );\n", "    }\n", "  }\n", "}"]}, {"cell_type": "markdown", "metadata": {}, "source": ["现在，如果我们运行代理并打印消息，我们可以看到代理记住了我们在本演示开始时添加到商店的食物偏好！"]}, {"cell_type": "code", "execution_count": 9, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["User: I'm hungry. What should I eat?\n", "Assistant: Since you prefer Italian food and love pizza, how about ordering a pizza? You could choose a classic Margherita or customize it with your favorite toppings, making sure to keep it non-spicy. Enjoy your meal!\n"]}], "source": ["\n", "let result = await agent.invoke({\n", "  messages: [\n", "    {\n", "      role: \"user\",\n", "      content: \"I'm hungry. What should I eat?\",\n", "    },\n", "  ],\n", "});\n", "\n", "printMessages(result.messages);"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### 储存新的记忆\n", "\n", "现在我们知道召回机制是有效的，让我们看看是否可以让我们的示例代理存储新的内存："]}, {"cell_type": "code", "execution_count": 10, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["User: Please remember that every Thursday is trash day.\n", "\tupsert_memory({\"content\":\"Every Thursday is trash day.\"})\n", "\t\tupsert_memory -> \"Stored memory.\"\n", "Assistant: I've remembered that every Thursday is trash day!\n"]}], "source": ["result = await agent.invoke({\n", "  messages: [\n", "    {\n", "      role: \"user\",\n", "      content: \"Please remember that every Thursday is trash day.\",\n", "    },\n", "  ],\n", "});\n", "\n", "printMessages(result.messages);"]}, {"cell_type": "markdown", "metadata": {}, "source": ["现在它已经存储了，让我们看看它是否还记得。\n", "\n", "请记住 - 这里没有检查点。每次我们调用代理时，这都是一次全新的对话。"]}, {"cell_type": "code", "execution_count": 11, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["User: When am I supposed to take out the garbage?\n", "Assistant: You take out the garbage every Thursday, as it's trash day for you.\n"]}], "source": ["result = await agent.invoke({\n", "  messages: [\n", "    {\n", "      role: \"user\",\n", "      content: \"When am I supposed to take out the garbage?\",\n", "    },\n", "  ],\n", "});\n", "\n", "printMessages(result.messages);"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 高级用法\n", "\n", "上面的示例非常简单，但希望它可以帮助您想象如何将存储和调用机制交织到代理中。在下面的部分中，我们将讨论更多主题，当您进入更高级的用例时，这些主题可能会对您有所帮助。\n", "\n", "### 多向量索引\n", "\n", "您可以分别存储和搜索记忆的不同方面，以提高召回率或从语义索引过程中省略某些字段。"]}, {"cell_type": "code", "execution_count": 12, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Expect mem 2\n", "Item: mem2; Score(0.58961641225287)\n", "Memory: Ate alone at home\n", "Emotion: felt a bit lonely\n"]}], "source": ["import { InMemoryStore } from \"@langchain/langgraph\";\n", "\n", "// 配置存储以嵌入记忆内容和情感背景\n", "const multiVectorStore = new InMemoryStore({\n", "  index: {\n", "    embeddings: embeddings,\n", "    dims: 1536,\n", "    fields: [\"memory\", \"emotional_context\"],\n", "  },\n", "});\n", "\n", "// 用不同的内容/情感对存储记忆\n", "await multiVectorStore.put([\"user_123\", \"memories\"], \"mem1\", {\n", "  memory: \"Had pizza with friends at Mario's\",\n", "  emotional_context: \"felt happy and connected\",\n", "  this_isnt_indexed: \"I prefer ravioli though\",\n", "});\n", "await multiVectorStore.put([\"user_123\", \"memories\"], \"mem2\", {\n", "  memory: \"Ate alone at home\",\n", "  emotional_context: \"felt a bit lonely\",\n", "  this_isnt_indexed: \"I like pie\",\n", "});\n", "\n", "// 专注于情绪状态的搜索 - 匹配 mem2\n", "const results = await multiVectorStore.search([\"user_123\", \"memories\"], {\n", "  query: \"times they felt isolated\",\n", "  limit: 1,\n", "});\n", "\n", "console.log(\"Expect mem 2\");\n", "\n", "for (const r of results) {\n", "  console.log(`Item: ${r.key}; Score(${r.score})`);\n", "  console.log(`Memory: ${r.value.memory}`);\n", "  console.log(`Emotion: ${r.value.emotional_context}`);\n", "}"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### 在存储时覆盖字段\n", "无论存储的默认配置如何，您都可以在使用 `put(..., { index: [...fields] })` 存储特定内存时覆盖要嵌入的字段。"]}, {"cell_type": "code", "execution_count": 13, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Expect mem1\n", "Item: mem1; Score(0.3375009515587189)\n", "Memory: I love spicy food\n", "Expect mem2\n", "Item: mem2; Score(0.1920732213417712)\n", "Memory: I love spicy food\n"]}], "source": ["import { InMemoryStore } from \"@langchain/langgraph\";\n", "\n", "const overrideStore = new InMemoryStore({\n", "  index: {\n", "    embeddings: embeddings,\n", "    dims: 1536,\n", "    // 默认嵌入内存字段\n", "    fields: [\"memory\"],\n", "  }\n", "});\n", "\n", "// 使用默认索引存储一个内存\n", "await overrideStore.put([\"user_123\", \"memories\"], \"mem1\", {\n", "  memory: \"I love spicy food\",\n", "  context: \"At a Thai restaurant\",\n", "});\n", "\n", "// 存储另一个内存，覆盖要嵌入的字段\n", "await overrideStore.put([\"user_123\", \"memories\"], \"mem2\", {\n", "  memory: \"I love spicy food\",\n", "  context: \"At a Thai restaurant\",\n", "  // 覆盖：仅嵌入上下文\n", "  index: [\"context\"]\n", "});\n", "\n", "// 搜索食物 - 匹配 mem1（使用默认字段）\n", "console.log(\"Expect mem1\");\n", "const results2 = await overrideStore.search([\"user_123\", \"memories\"], {\n", "  query: \"what food do they like\",\n", "  limit: 1,\n", "});\n", "\n", "for (const r of results2) {\n", "  console.log(`Item: ${r.key}; Score(${r.score})`);\n", "  console.log(`Memory: ${r.value.memory}`);\n", "}\n", "\n", "// 搜索餐厅氛围 - 匹配 mem2（使用覆盖字段）\n", "console.log(\"Expect mem2\");\n", "const results3 = await overrideStore.search([\"user_123\", \"memories\"], {\n", "  query: \"restaurant environment\",\n", "  limit: 1,\n", "});\n", "\n", "for (const r of results3) {\n", "  console.log(`Item: ${r.key}; Score(${r.score})`);\n", "  console.log(`Memory: ${r.value.memory}`);\n", "}"]}], "metadata": {"kernelspec": {"display_name": "TypeScript", "language": "typescript", "name": "tslab"}, "language_info": {"codemirror_mode": {"mode": "typescript", "name": "javascript", "typescript": true}, "file_extension": ".ts", "mimetype": "text/typescript", "name": "typescript", "version": "3.7.2"}}, "nbformat": 4, "nbformat_minor": 4}