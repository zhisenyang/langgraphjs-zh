{"cells": [{"cell_type": "markdown", "id": "562ddb82", "metadata": {}, "source": ["# 如何传输图表的完整状态\n", "\n", "LangGraph 支持多种流模式。主要有：\n", "\n", "- `values`：此流模式流回图表的值。这是\n", "**调用每个节点后图的完整状态**。\n", "- `updates`：此流模式将更新流回图表。这是\n", "**在调用每个节点后更新图的状态**。\n", "\n", "本指南涵盖 `streamMode=\"values\"`。"]}, {"cell_type": "code", "execution_count": 1, "id": "8e76833b", "metadata": {"lines_to_next_cell": 2}, "outputs": [], "source": ["// process.env.OPENAI_API_KEY = \"sk-...\";"]}, {"cell_type": "markdown", "id": "ab95dc97", "metadata": {}, "source": ["## 定义状态\n", "\n", "状态是图中所有节点的接口。\n"]}, {"cell_type": "code", "execution_count": 2, "id": "1648124b", "metadata": {"lines_to_next_cell": 2}, "outputs": [], "source": ["import { Annotation } from \"@langchain/langgraph\";\n", "import { BaseMessage } from \"@langchain/core/messages\";\n", "\n", "const StateAnnotation = Annotation.Root({\n", "  messages: Annotation<BaseMessage[]>({\n", "    reducer: (x, y) => x.concat(y),\n", "  }),\n", "});"]}, {"cell_type": "markdown", "id": "da50fbd8", "metadata": {}, "source": ["## 设置工具\n", "\n", "我们将首先定义我们想要使用的工具。对于这个简单的例子，我们将\n", "使用创建占位符搜索引擎。然而，创建起来确实很容易\n", "您自己的工具 - 请参阅文档\n", "[此处](https://js.langchain.com/docs/how_to/custom_tools) 了解如何操作\n", "那。\n"]}, {"cell_type": "code", "execution_count": 3, "id": "a8f1ae1c", "metadata": {"lines_to_next_cell": 2}, "outputs": [], "source": ["import { tool } from \"@langchain/core/tools\";\n", "import { z } from \"zod\";\n", "\n", "const searchTool = tool(async ({ query: _query }: { query: string }) => {\n", "  // 这是实际实现的占位符\n", "  return \"Cold, with a low of 3℃\";\n", "}, {\n", "  name: \"search\",\n", "  description:\n", "    \"Use to surf the web, fetch current information, check the weather, and retrieve other information.\",\n", "  schema: z.object({\n", "    query: z.string().describe(\"The query to use in your search.\"),\n", "  }),\n", "});\n", "\n", "await searchTool.invoke({ query: \"What's the weather like?\" });\n", "\n", "const tools = [searchTool];"]}, {"cell_type": "markdown", "id": "19b27cb3", "metadata": {}, "source": ["我们现在可以将这些工具包装在一个简单的\n", "[ToolNode](/langgraphjs/reference/classes/langgraph_prebuilt.ToolNode.html)。\n", "每当工具（函数）被调用时，该对象就会实际运行它们\n", "我们的法学硕士。\n"]}, {"cell_type": "code", "execution_count": 4, "id": "f02278b1", "metadata": {"lines_to_next_cell": 2}, "outputs": [], "source": ["import { ToolNode } from \"@langchain/langgraph/prebuilt\";\n", "\n", "const toolNode = new ToolNode(tools);"]}, {"cell_type": "markdown", "id": "dd55ee5a", "metadata": {}, "source": ["## 设置模型\n", "\n", "现在我们将加载\n", "[聊天模型](https://js.langchain.com/docs/concepts/chat_models/)。\n", "\n", "1.它应该与消息一起使用。我们将以表格形式代表所有代理状态\n", "消息，因此它需要能够与它们很好地配合。\n", "2.它应该与\n", "[工具调用](https://js.langchain.com/docs/how_to/tool_calling/#passing-tools-to-llms),\n", "这意味着它可以在响应中返回函数参数。\n", "\n", "<div class=\"警告提示\">\n", "<p class=\"admonition-title\">注意</p>\n", "<p>\n", "这些模型要求不是使用 LangGraph 的一般要求 - 它们只是这个示例的要求。\n", "</p>\n", "</div>"]}, {"cell_type": "code", "execution_count": 5, "id": "9c7210e7", "metadata": {"lines_to_next_cell": 2}, "outputs": [], "source": ["import { ChatOpenAI } from \"@langchain/openai\";\n", "\n", "const model = new ChatOpenAI({ model: \"gpt-4o\" });"]}, {"cell_type": "markdown", "id": "73e59248", "metadata": {}, "source": ["完成此操作后，我们应该确保模型知道它具有这些\n", "可供调用的工具。我们可以通过调用来做到这一点\n", "[bindTools](https://v01.api.js.langchain.com/classes/langchain_core_language_models_chat_models.BaseChatModel.html#bindTools)。"]}, {"cell_type": "code", "execution_count": 6, "id": "b4ff23ee", "metadata": {"lines_to_next_cell": 2}, "outputs": [], "source": ["const boundModel = model.bindTools(tools);"]}, {"cell_type": "markdown", "id": "dbe67356", "metadata": {}, "source": ["## 定义图表\n", "\n", "我们现在可以把它们放在一起。"]}, {"cell_type": "code", "execution_count": 7, "id": "0ba603bb", "metadata": {}, "outputs": [], "source": ["import { END, START, StateGraph } from \"@langchain/langgraph\";\n", "import { AIMessage } from \"@langchain/core/messages\";\n", "\n", "const routeMessage = (state: typeof StateAnnotation.State) => {\n", "  const { messages } = state;\n", "  const lastMessage = messages[messages.length - 1] as AIMessage;\n", "  // 如果没有调用任何工具，我们就可以完成（响应用户）\n", "  if (!lastMessage?.tool_calls?.length) {\n", "    return END;\n", "  }\n", "  // 否则，如果有，我们继续并调用工具\n", "  return \"tools\";\n", "};\n", "\n", "const callModel = async (\n", "  state: typeof StateAnnotation.State,\n", ") => {\n", "  // 对于 @langchain/core < 0.2.3 的版本，您必须调用 `.stream()`\n", "  // 并从块聚合消息而不是调用“.invoke()”。\n", "  const { messages } = state;\n", "  const responseMessage = await boundModel.invoke(messages);\n", "  return { messages: [responseMessage] };\n", "};\n", "\n", "const workflow = new StateGraph(StateAnnotation)\n", "  .addNode(\"agent\", callModel)\n", "  .addNode(\"tools\", toolNode)\n", "  .addEdge(START, \"agent\")\n", "  .addConditionalEdges(\"agent\", routeMessage)\n", "  .addEdge(\"tools\", \"agent\");\n", "\n", "const graph = workflow.compile();"]}, {"cell_type": "markdown", "id": "a1ab3ad3", "metadata": {}, "source": ["## 流值\n", "\n", "我们现在可以与代理进行交互。在交互之间你可以获取和更新\n", "状态。\n"]}, {"cell_type": "code", "execution_count": 8, "id": "cbcf7c39", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["[ [ 'user', \"what's the weather in sf\" ] ]\n", "\n", "====\n", "\n", "[\n", "  [ 'user', \"what's the weather in sf\" ],\n", "  AIMessage {\n", "    \"id\": \"chatcmpl-9y660d49eLzT7DZeBk2ZmX8C5f0LU\",\n", "    \"content\": \"\",\n", "    \"additional_kwargs\": {\n", "      \"tool_calls\": [\n", "        {\n", "          \"id\": \"call_iD5Wk4vPsTckffDKJpEQaMkg\",\n", "          \"type\": \"function\",\n", "          \"function\": \"[Object]\"\n", "        }\n", "      ]\n", "    },\n", "    \"response_metadata\": {\n", "      \"tokenUsage\": {\n", "        \"completionTokens\": 17,\n", "        \"promptTokens\": 70,\n", "        \"totalTokens\": 87\n", "      },\n", "      \"finish_reason\": \"tool_calls\",\n", "      \"system_fingerprint\": \"fp_3aa7262c27\"\n", "    },\n", "    \"tool_calls\": [\n", "      {\n", "        \"name\": \"search\",\n", "        \"args\": {\n", "          \"query\": \"current weather in San Francisco\"\n", "        },\n", "        \"type\": \"tool_call\",\n", "        \"id\": \"call_iD5Wk4vPsTckffDKJpEQaMkg\"\n", "      }\n", "    ],\n", "    \"invalid_tool_calls\": [],\n", "    \"usage_metadata\": {\n", "      \"input_tokens\": 70,\n", "      \"output_tokens\": 17,\n", "      \"total_tokens\": 87\n", "    }\n", "  }\n", "]\n", "\n", "====\n", "\n", "[\n", "  [ 'user', \"what's the weather in sf\" ],\n", "  AIMessage {\n", "    \"id\": \"chatcmpl-9y660d49eLzT7DZeBk2ZmX8C5f0LU\",\n", "    \"content\": \"\",\n", "    \"additional_kwargs\": {\n", "      \"tool_calls\": [\n", "        {\n", "          \"id\": \"call_iD5Wk4vPsTckffDKJpEQaMkg\",\n", "          \"type\": \"function\",\n", "          \"function\": \"[Object]\"\n", "        }\n", "      ]\n", "    },\n", "    \"response_metadata\": {\n", "      \"tokenUsage\": {\n", "        \"completionTokens\": 17,\n", "        \"promptTokens\": 70,\n", "        \"totalTokens\": 87\n", "      },\n", "      \"finish_reason\": \"tool_calls\",\n", "      \"system_fingerprint\": \"fp_3aa7262c27\"\n", "    },\n", "    \"tool_calls\": [\n", "      {\n", "        \"name\": \"search\",\n", "        \"args\": {\n", "          \"query\": \"current weather in San Francisco\"\n", "        },\n", "        \"type\": \"tool_call\",\n", "        \"id\": \"call_iD5Wk4vPsTckffDKJpEQaMkg\"\n", "      }\n", "    ],\n", "    \"invalid_tool_calls\": [],\n", "    \"usage_metadata\": {\n", "      \"input_tokens\": 70,\n", "      \"output_tokens\": 17,\n", "      \"total_tokens\": 87\n", "    }\n", "  },\n", "  ToolMessage {\n", "    \"content\": \"Cold, with a low of 3℃\",\n", "    \"name\": \"search\",\n", "    \"additional_kwargs\": {},\n", "    \"response_metadata\": {},\n", "    \"tool_call_id\": \"call_iD5Wk4vPsTckffDKJpEQaMkg\"\n", "  }\n", "]\n", "\n", "====\n", "\n", "[\n", "  [ 'user', \"what's the weather in sf\" ],\n", "  AIMessage {\n", "    \"id\": \"chatcmpl-9y660d49eLzT7DZeBk2ZmX8C5f0LU\",\n", "    \"content\": \"\",\n", "    \"additional_kwargs\": {\n", "      \"tool_calls\": [\n", "        {\n", "          \"id\": \"call_iD5Wk4vPsTckffDKJpEQaMkg\",\n", "          \"type\": \"function\",\n", "          \"function\": \"[Object]\"\n", "        }\n", "      ]\n", "    },\n", "    \"response_metadata\": {\n", "      \"tokenUsage\": {\n", "        \"completionTokens\": 17,\n", "        \"promptTokens\": 70,\n", "        \"totalTokens\": 87\n", "      },\n", "      \"finish_reason\": \"tool_calls\",\n", "      \"system_fingerprint\": \"fp_3aa7262c27\"\n", "    },\n", "    \"tool_calls\": [\n", "      {\n", "        \"name\": \"search\",\n", "        \"args\": {\n", "          \"query\": \"current weather in San Francisco\"\n", "        },\n", "        \"type\": \"tool_call\",\n", "        \"id\": \"call_iD5Wk4vPsTckffDKJpEQaMkg\"\n", "      }\n", "    ],\n", "    \"invalid_tool_calls\": [],\n", "    \"usage_metadata\": {\n", "      \"input_tokens\": 70,\n", "      \"output_tokens\": 17,\n", "      \"total_tokens\": 87\n", "    }\n", "  },\n", "  ToolMessage {\n", "    \"content\": \"Cold, with a low of 3℃\",\n", "    \"name\": \"search\",\n", "    \"additional_kwargs\": {},\n", "    \"response_metadata\": {},\n", "    \"tool_call_id\": \"call_iD5Wk4vPsTckffDKJpEQaMkg\"\n", "  },\n", "  AIMessage {\n", "    \"id\": \"chatcmpl-9y660ZKNXvziVJze0X5aTlZ5IoN35\",\n", "    \"content\": \"Currently, in San Francisco, it's cold with a temperature of around 3℃ (37.4°F).\",\n", "    \"additional_kwargs\": {},\n", "    \"response_metadata\": {\n", "      \"tokenUsage\": {\n", "        \"completionTokens\": 23,\n", "        \"promptTokens\": 103,\n", "        \"totalTokens\": 126\n", "      },\n", "      \"finish_reason\": \"stop\",\n", "      \"system_fingerprint\": \"fp_3aa7262c27\"\n", "    },\n", "    \"tool_calls\": [],\n", "    \"invalid_tool_calls\": [],\n", "    \"usage_metadata\": {\n", "      \"input_tokens\": 103,\n", "      \"output_tokens\": 23,\n", "      \"total_tokens\": 126\n", "    }\n", "  }\n", "]\n", "\n", "====\n", "\n"]}], "source": ["let inputs = { messages: [{ role: \"user\", content: \"what's the weather in sf\" }] };\n", "\n", "for await (\n", "  const chunk of await graph.stream(inputs, {\n", "    streamMode: \"values\",\n", "  })\n", ") {\n", "  console.log(chunk[\"messages\"]);\n", "  console.log(\"\\n====\\n\");\n", "}"]}], "metadata": {"kernelspec": {"display_name": "TypeScript", "language": "typescript", "name": "tslab"}, "language_info": {"codemirror_mode": {"mode": "typescript", "name": "javascript", "typescript": true}, "file_extension": ".ts", "mimetype": "text/typescript", "name": "typescript", "version": "3.7.2"}}, "nbformat": 4, "nbformat_minor": 5}