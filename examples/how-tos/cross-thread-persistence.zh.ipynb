{"cells": [{"attachments": {}, "cell_type": "markdown", "id": "d2eecb96-cf0e-47ed-8116-88a7eaa4236d", "metadata": {}, "source": ["# 如何将跨线程持久性添加到图表中\n", "\n", "<div class=\"警告提示\">\n", "<p class=\"admonition-title\">先决条件</p>\n", "<p>\n", "本指南假设您熟悉以下内容：\n", "<ul>\n", "<li>\n", "<a href=\"https://langchain-ai.github.io/langgraphjs/concepts/persistence/\">\n", "坚持\n", "</a>\n", "</li>\n", "<li>\n", "<a href=\"https://langchain-ai.github.io/langgraphjs/concepts/memory/\">\n", "记忆\n", "</a>\n", "</li>\n", "<li>\n", "<a href=\"https://js.langchain.com/docs/concepts/#chat-models\">\n", "聊天模型\n", "</a>\n", "</li>\n", "</ul>\n", "</p>\n", "</div>\n", "\n", "在[上一篇指南](https://langchain-ai.github.io/langgraphjs/how-tos/persistence.ipynb)中，您学习了如何在单个[线程]()上跨多个交互持久保存图形状态。LangGraph.js 还允许您跨**多个线程**保存数据。例如，您可以将有关用户的信息（他们的姓名或首选项）存储在共享内存中，并在新的对话线程中重用它们。\n", "\n", "在本指南中，我们将展示如何构建和使用具有使用 [Store](https://langchain-ai.github.io/langgraphjs/reference/classes/checkpoint.BaseStore.html) 接口实现的共享内存的图。\n", "\n", "<div class=\"警告说明\">\n", "<p class=\"admonition-title\">注意</p>\n", "<p>\n", "LangGraph.js <code>v0.2.10</code> 中添加了对本指南中使用的 <code><a href=\"https://langchain-ai.github.io/langgraphjs/reference/classes/checkpoint.BaseStore.html\">Store</a></code> API 的支持。\n", "</p>\n", "</div>\n", "\n", "## 设置\n", "\n", "首先，让我们安装所需的软件包并设置 API 密钥。\n", "\n", "<div class=\"警告提示\">\n", "<p class=\"admonition-title\">设置 <a href=\"https://smith.langchain.com\">LangSmith</a> 进行 LangGraph 开发</p>\n", "<p style=\"padding-top: 5px;\">\n", "注册 LangSmith 以快速发现问题并提高 LangGraph 项目的性能。LangSmith 允许您使用跟踪数据来调试、测试和监控使用 LangGraph 构建的 LLM 应用程序 - 在<a href=\"https://docs.smith.langchain.com\">此处</a>了解有关如何开始的更多信息。\n", "</p>\n", "</div>"]}, {"cell_type": "code", "execution_count": null, "id": "3457aadf", "metadata": {}, "outputs": [], "source": ["// process.env.OPENAI_API_KEY = \"sk_...\";\n", "\n", "// 可选，在 LangSmith 中添加跟踪\n", "// process.env.LANGCHAIN_API_KEY = \"lsv2__...\";\n", "// process.env.ANTHROPIC_API_KEY = \"你的 API 密钥\";\n", "// process.env.LANGCHAIN_TRACING_V2 = \"true\";\n", "// process.env.LANGCHAIN_PROJECT = \"跨线程持久化：LangGraphJS\";"]}, {"cell_type": "markdown", "id": "c4c550b5-1954-496b-8b9d-800361af17dc", "metadata": {}, "source": ["## 定义商店\n", "\n", "在此示例中，我们将创建一个能够检索有关用户首选项的信息的图表。我们将通过定义一个 `InMemoryStore` 来实现这一点 - 一个可以在内存中存储数据并查询该数据的对象。然后，我们将在编译图表时传递 store 对象。这允许图中的每个节点访问存储：当您定义节点函数时，您可以定义 `store` 关键字参数，LangGraph 将自动传递您编译图时使用的存储对象。\n", "\n", "使用 `Store` 接口存储对象时，您定义两件事：\n", "\n", "* 对象的命名空间，一个元组（类似于目录）\n", "* 对象键（类似于文件名）\n", "\n", "在我们的示例中，我们将使用 `(\"memories\", <userId>)` 作为命名空间，并使用随机 UUID 作为每个新内存的密钥。\n", "\n", "重要的是，为了确定用户，我们将通过节点函数的 config 关键字参数传递 `userId`。\n", "\n", "我们首先定义一个 `InMemoryStore`，它已经填充了有关用户的一些记忆。"]}, {"cell_type": "code", "execution_count": 1, "id": "a7f303d6-612e-4e34-bf36-29d4ed25d802", "metadata": {}, "outputs": [], "source": ["import { InMemoryStore } from \"@langchain/langgraph\";\n", "\n", "const inMemoryStore = new InMemoryStore();"]}, {"cell_type": "markdown", "id": "3389c9f4-226d-40c7-8bfc-ee8aac24f79d", "metadata": {}, "source": ["## 创建图表"]}, {"cell_type": "code", "execution_count": null, "id": "2a30a362-528c-45ee-9df6-630d2d843588", "metadata": {}, "outputs": [], "source": ["import { v4 as uuidv4 } from \"uuid\";\n", "import { ChatAnthropic } from \"@langchain/anthropic\";\n", "import { BaseMessage } from \"@langchain/core/messages\";\n", "import {\n", "  Annotation,\n", "  StateGraph,\n", "  START,\n", "  MemorySaver,\n", "  LangGraphRunnableConfig,\n", "  messagesStateReducer,\n", "} from \"@langchain/langgraph\";\n", "\n", "const StateAnnotation = Annotation.Root({\n", "  messages: Annotation<BaseMessage[]>({\n", "    reducer: messagesStateReducer,\n", "    default: () => [],\n", "  }),\n", "});\n", "\n", "const model = new ChatAnthropic({ modelName: \"claude-3-5-sonnet-20240620\" });\n", "\n", "// 注意：我们将 Store 参数传递给节点——\n", "// 这是我们用来编译图表的 Store\n", "const callModel = async (\n", "  state: typeof StateAnnotation.State,\n", "  config: LangGraphRunnableConfig\n", "): Promise<{ messages: any }> => {\n", "  const store = config.store;\n", "  if (!store) {\n", "    if (!store) {\n", "      throw new Error(\"store is required when compiling the graph\");\n", "    }\n", "  }\n", "  if (!config.configurable?.userId) {\n", "    throw new Error(\"userId is required in the config\");\n", "  }\n", "  const namespace = [\"memories\", config.configurable?.userId];\n", "  const memories = await store.search(namespace);\n", "  const info = memories.map((d) => d.value.data).join(\"\\n\");\n", "  const systemMsg = `You are a helpful assistant talking to the user. User info: ${info}`;\n", "\n", "  // 如果用户要求模型记住，则存储新的记忆\n", "  const lastMessage = state.messages[state.messages.length - 1];\n", "  if (\n", "    typeof lastMessage.content === \"string\" &&\n", "    lastMessage.content.toLowerCase().includes(\"remember\")\n", "  ) {\n", "    await store.put(namespace, uuidv4(), { data: lastMessage.content });\n", "  }\n", "\n", "  const response = await model.invoke([\n", "    { type: \"system\", content: systemMsg },\n", "    ...state.messages,\n", "  ]);\n", "  return { messages: response };\n", "};\n", "\n", "const builder = new StateGraph(StateAnnotation)\n", "  .addNode(\"call_model\", callModel)\n", "  .addEdge(START, \"call_model\");\n", "\n", "// 注意：编译图表时我们在此处传递存储对象\n", "const graph = builder.compile({\n", "  checkpointer: new MemorySaver(),\n", "  store: inMemoryStore,\n", "});\n", "// 如果您使用 LangGraph Cloud 或 LangGraph Studio，则在编译图表时无需传递存储或检查点，因为它是自动完成的。\n"]}, {"cell_type": "markdown", "id": "f22a4a18-67e4-4f0b-b655-a29bbe202e1c", "metadata": {}, "source": ["<div class=\"警告提示\">\n", "<p class=\"admonition-title\">注意</p>\n", "<p>\n", "如果您使用 LangGraph Cloud 或 LangGraph Studio，则在编译图表时<strong>不需要</strong>传递 store，因为它是自动完成的。\n", "</p>\n", "</div>"]}, {"cell_type": "markdown", "id": "552d4e33-556d-4fa5-8094-2a076bc21529", "metadata": {}, "source": ["## 运行图表！"]}, {"cell_type": "markdown", "id": "1842c626-6cd9-4f58-b549-58978e478098", "metadata": {}, "source": ["现在让我们在配置中指定一个用户 ID 并告诉模型我们的名字："]}, {"cell_type": "code", "execution_count": 3, "id": "c871a073-a466-46ad-aafe-2b870831057e", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["HumanMessage {\n", "  \"id\": \"ef28a40a-fd75-4478-929a-5413f2a6b044\",\n", "  \"content\": \"Hi! Remember: my name is Bob\",\n", "  \"additional_kwargs\": {},\n", "  \"response_metadata\": {}\n", "}\n", "AIMessage {\n", "  \"id\": \"msg_01UcHJnSAuVDFuDmqaYkxWAf\",\n", "  \"content\": \"Hello Bob! It's nice to meet you. I'll remember that your name is Bob. How can I assist you today?\",\n", "  \"additional_kwargs\": {\n", "    \"id\": \"msg_01UcHJnSAuVDFuDmqaYkxWAf\",\n", "    \"type\": \"message\",\n", "    \"role\": \"assistant\",\n", "    \"model\": \"claude-3-5-sonnet-20240620\",\n", "    \"stop_reason\": \"end_turn\",\n", "    \"stop_sequence\": null,\n", "    \"usage\": {\n", "      \"input_tokens\": 28,\n", "      \"output_tokens\": 29\n", "    }\n", "  },\n", "  \"response_metadata\": {\n", "    \"id\": \"msg_01UcHJnSAuVDFuDmqaYkxWAf\",\n", "    \"model\": \"claude-3-5-sonnet-20240620\",\n", "    \"stop_reason\": \"end_turn\",\n", "    \"stop_sequence\": null,\n", "    \"usage\": {\n", "      \"input_tokens\": 28,\n", "      \"output_tokens\": 29\n", "    },\n", "    \"type\": \"message\",\n", "    \"role\": \"assistant\"\n", "  },\n", "  \"tool_calls\": [],\n", "  \"invalid_tool_calls\": [],\n", "  \"usage_metadata\": {\n", "    \"input_tokens\": 28,\n", "    \"output_tokens\": 29,\n", "    \"total_tokens\": 57\n", "  }\n", "}\n"]}], "source": ["let config = { configurable: { thread_id: \"1\", userId: \"1\" } };\n", "let inputMessage = { type: \"user\", content: \"Hi! Remember: my name is Bob\" };\n", "\n", "for await (const chunk of await graph.stream(\n", "  { messages: [inputMessage] },\n", "  { ...config, streamMode: \"values\" }\n", ")) {\n", "  console.log(chunk.messages[chunk.messages.length - 1]);\n", "}\n"]}, {"cell_type": "code", "execution_count": 4, "id": "d862be40-1f8a-4057-81c4-b7bf073dc4c1", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["HumanMessage {\n", "  \"id\": \"eaaa4e1c-1560-4b0a-9c2d-396313cb000c\",\n", "  \"content\": \"what is my name?\",\n", "  \"additional_kwargs\": {},\n", "  \"response_metadata\": {}\n", "}\n", "AIMessage {\n", "  \"id\": \"msg_01VfqUerYCND1JuWGvbnAacP\",\n", "  \"content\": \"Your name is Bob. It's nice to meet you, Bob!\",\n", "  \"additional_kwargs\": {\n", "    \"id\": \"msg_01VfqUerYCND1JuWGvbnAacP\",\n", "    \"type\": \"message\",\n", "    \"role\": \"assistant\",\n", "    \"model\": \"claude-3-5-sonnet-20240620\",\n", "    \"stop_reason\": \"end_turn\",\n", "    \"stop_sequence\": null,\n", "    \"usage\": {\n", "      \"input_tokens\": 33,\n", "      \"output_tokens\": 17\n", "    }\n", "  },\n", "  \"response_metadata\": {\n", "    \"id\": \"msg_01VfqUerYCND1JuWGvbnAacP\",\n", "    \"model\": \"claude-3-5-sonnet-20240620\",\n", "    \"stop_reason\": \"end_turn\",\n", "    \"stop_sequence\": null,\n", "    \"usage\": {\n", "      \"input_tokens\": 33,\n", "      \"output_tokens\": 17\n", "    },\n", "    \"type\": \"message\",\n", "    \"role\": \"assistant\"\n", "  },\n", "  \"tool_calls\": [],\n", "  \"invalid_tool_calls\": [],\n", "  \"usage_metadata\": {\n", "    \"input_tokens\": 33,\n", "    \"output_tokens\": 17,\n", "    \"total_tokens\": 50\n", "  }\n", "}\n"]}], "source": ["config = { configurable: { thread_id: \"2\", userId: \"1\" } };\n", "inputMessage = { type: \"user\", content: \"what is my name?\" };\n", "\n", "for await (const chunk of await graph.stream(\n", "  { messages: [inputMessage] },\n", "  { ...config, streamMode: \"values\" }\n", ")) {\n", "  console.log(chunk.messages[chunk.messages.length - 1]);\n", "}"]}, {"cell_type": "markdown", "id": "80fd01ec-f135-4811-8743-daff8daea422", "metadata": {}, "source": ["我们现在可以检查内存存储并验证我们实际上已经为用户保存了内存："]}, {"cell_type": "code", "execution_count": 5, "id": "76cde493-89cf-4709-a339-207d2b7e9ea7", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["{ data: 'Hi! Remember: my name is Bob' }\n"]}], "source": ["const memories = await inMemoryStore.search([\"memories\", \"1\"]);\n", "for (const memory of memories) {\n", "    console.log(await memory.value);\n", "}"]}, {"cell_type": "markdown", "id": "23f5d7eb-af23-4131-b8fd-2a69e74e6e55", "metadata": {}, "source": ["现在让我们为另一个用户运行该图，以验证有关第一个用户的记忆是否是独立的："]}, {"cell_type": "code", "execution_count": 6, "id": "d362350b-d730-48bd-9652-983812fd7811", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["HumanMessage {\n", "  \"id\": \"1006b149-de8d-4d8e-81f4-c78c51a7144b\",\n", "  \"content\": \"what is my name?\",\n", "  \"additional_kwargs\": {},\n", "  \"response_metadata\": {}\n", "}\n", "AIMessage {\n", "  \"id\": \"msg_01MjpYZ65NjwZMYq42BWa2Ze\",\n", "  \"content\": \"I apologize, but I don't have any information about your name or personal details. As an AI assistant, I don't have access to personal information about individual users unless it's specifically provided in our conversation. Is there something else I can help you with?\",\n", "  \"additional_kwargs\": {\n", "    \"id\": \"msg_01MjpYZ65NjwZMYq42BWa2Ze\",\n", "    \"type\": \"message\",\n", "    \"role\": \"assistant\",\n", "    \"model\": \"claude-3-5-sonnet-20240620\",\n", "    \"stop_reason\": \"end_turn\",\n", "    \"stop_sequence\": null,\n", "    \"usage\": {\n", "      \"input_tokens\": 25,\n", "      \"output_tokens\": 56\n", "    }\n", "  },\n", "  \"response_metadata\": {\n", "    \"id\": \"msg_01MjpYZ65NjwZMYq42BWa2Ze\",\n", "    \"model\": \"claude-3-5-sonnet-20240620\",\n", "    \"stop_reason\": \"end_turn\",\n", "    \"stop_sequence\": null,\n", "    \"usage\": {\n", "      \"input_tokens\": 25,\n", "      \"output_tokens\": 56\n", "    },\n", "    \"type\": \"message\",\n", "    \"role\": \"assistant\"\n", "  },\n", "  \"tool_calls\": [],\n", "  \"invalid_tool_calls\": [],\n", "  \"usage_metadata\": {\n", "    \"input_tokens\": 25,\n", "    \"output_tokens\": 56,\n", "    \"total_tokens\": 81\n", "  }\n", "}\n"]}], "source": ["config = { configurable: { thread_id: \"3\", userId: \"2\" } };\n", "inputMessage = { type: \"user\", content: \"what is my name?\" };\n", "\n", "for await (const chunk of await graph.stream(\n", "  { messages: [inputMessage] },\n", "  { ...config, streamMode: \"values\" }\n", ")) {\n", "  console.log(chunk.messages[chunk.messages.length - 1]);\n", "}"]}], "metadata": {"kernelspec": {"display_name": "TypeScript", "language": "typescript", "name": "tslab"}, "language_info": {"codemirror_mode": {"mode": "typescript", "name": "javascript", "typescript": true}, "file_extension": ".ts", "mimetype": "text/typescript", "name": "typescript", "version": "3.7.2"}}, "nbformat": 4, "nbformat_minor": 5}