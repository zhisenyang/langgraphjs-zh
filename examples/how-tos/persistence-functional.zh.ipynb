{"cells": [{"cell_type": "markdown", "id": "51466c8d-8ce4-4b3d-be4e-18fdbeda5f53", "metadata": {}, "source": ["# 如何添加线程级持久化（函数式API）\n", "\n", "!!!信息“先决条件”\n", "\n", "本指南假设您熟悉以下内容：\n", "\n", "- [功能 API](../../concepts/function_api/)\n", "- [持久性](../../概念/持久性/)\n", "- [记忆](../../概念/记忆/)\n", "- [聊天模型](https://js.langchain.com/docs/concepts/chat_models/)\n", "\n", "许多人工智能应用程序需要内存来在同一线程上的多个交互之间共享上下文（../../concepts/persistence#threads）（例如，多轮对话）。在 LangGraph 函数式 API 中，这种内存可以使用 [线程级持久性](/langgraphjs/concepts/persistence) 添加到任何 [entrypoint()](/langgraphjs/reference/functions/langgraph.entrypoint-1.html) 工作流程中。\n", "\n", "创建 LangGraph 工作流程时，您可以使用 [checkpointer](/langgraphjs/reference/classes/checkpoint.BaseCheckpointSaver.html) 将其设置为保留其结果：\n", "\n", "\n", "1. 创建检查点实例：\n", "    ```ts\n", "    import { MemorySaver } from \"@langchain/langgraph\";\n", "    \n", "    const checkpointer = new MemorySaver();\n", "    ```\n", "2. 将 `checkpointer` 实例传递给 `entrypoint()` 包装函数：\n", "    ```ts\n", "    import { entrypoint } from \"@langchain/langgraph\";\n", "    const workflow = entrypoint({\n", "      name: \"workflow\",\n", "      checkpointer,\n", "    }, async (inputs) => {\n", "      ...\n", "    });\n", "    ```\n", "3. 从工作流中之前的执行中检索 `previous` 状态：\n", "    ```ts\n", "    import { entrypoint, getPreviousState } from \"@langchain/langgraph\";\n", "    \n", "    const workflow = entrypoint({\n", "      name: \"workflow\",\n", "      checkpointer,\n", "    }, async (inputs) => {\n", "      const previous = getPreviousState();\n", "      const result = doSomething(previous, inputs);\n", "      ...\n", "    });\n", "    ```\n", "4. （可选）选择将从工作流程返回哪些值以及检查点将哪些值保存为 `previous`：\n", "    ```ts\n", "    import { entrypoint, getPreviousState } from \"@langchain/langgraph\";\n", "    \n", "    const workflow = entrypoint({\n", "      name: \"workflow\",\n", "      checkpointer,\n", "    }, async (inputs) => {\n", "      const previous = getPreviousState();\n", "      const result = doSomething(previous, inputs);\n", "      ...\n", "      return entrypoint.final({\n", "        value: result,\n", "        save: combineState(inputs, result),\n", "      });\n", "    });\n", "    ```\n", "本指南展示了如何将线程级持久性添加到工作流程中。\n", "\n", "!!!提示“注意”\n", "\n", "如果您需要在多个对话或用户之间 __shared__ 的内存（跨线程持久性），请查看此[操作指南](../cross-thread-persistence-function)。\n", "\n", "!!!提示“注意”\n", "\n", "如果您需要向 `StateGraph` 添加线程级持久性，请查看此[操作指南](../persistence)。"]}, {"cell_type": "markdown", "id": "f0ed46a8-effe-4596-b0e1-a6a29ee16f5c", "metadata": {}, "source": ["## 设置\n", "\n", "!!!注意兼容性\n", "\n", "本指南需要 `@langchain/langgraph>=0.2.42`。\n", "\n", "首先，安装本示例所需的依赖项：\n", "```bash\n", "npm install @langchain/langgraph @langchain/anthropic @langchain/core zod\n", "```\n", "接下来，我们需要为 Anthropic 设置 API 密钥（我们将使用的 LLM）：\n", "```typescript\n", "process.env.ANTHROPIC_API_KEY = \"YOUR_API_KEY\";\n", "```\n", "!!!提示“为 LangGraph 开发设置 [LangSmith](https://smith.langchain.com)”\n", "\n", "注册 LangSmith 以快速发现问题并提高 LangGraph 项目的性能。LangSmith 允许您使用跟踪数据来调试、测试和监控使用 LangGraph 构建的 LLM 应用程序 — 在[此处](https://docs.smith.langchain.com)了解有关如何开始的更多信息"]}, {"cell_type": "markdown", "id": "4cf509bc", "metadata": {}, "source": ["## 示例：具有短期记忆的简单聊天机器人\n", "\n", "我们将使用一个包含单个任务的工作流程来调用[聊天模型](https://js.langchain.com/docs/concepts/chat_models/)。\n", "\n", "让我们首先定义我们将使用的模型："]}, {"cell_type": "code", "execution_count": 1, "id": "892b54b9-75f0-4804-9ed0-88b5e5532989", "metadata": {}, "outputs": [], "source": ["import { ChatAnthropic } from \"@langchain/anthropic\";\n", "\n", "const model = new ChatAnthropic({\n", "  model: \"claude-3-5-sonnet-latest\",\n", "});"]}, {"cell_type": "markdown", "id": "7b7a2792-982b-4e47-83eb-0c594725d1c1", "metadata": {}, "source": ["现在我们可以定义我们的任务和工作流程。为了添加持久性，我们需要将 [Checkpointer](https://langchain-ai.github.io/langgraph/reference/checkpoints/#langgraph.checkpoint.base.BaseCheckpointSaver) 传递给 [entrypoint()](/langgraphjs/reference/functions/langgraph.entrypoint-1.html) 包装函数。"]}, {"cell_type": "code", "execution_count": 2, "id": "87326ea6-34c5-46da-a41f-dda26ef9bd74", "metadata": {}, "outputs": [], "source": ["import type { BaseMessage, BaseMessageLike } from \"@langchain/core/messages\";\n", "import {\n", "  addMessages,\n", "  entrypoint,\n", "  task,\n", "  getPreviousState,\n", "  MemorySaver,\n", "} from \"@langchain/langgraph\";\n", "\n", "const callModel = task(\"callModel\", async (messages: BaseMessageLike[]) => {\n", "  const response = model.invoke(messages);\n", "  return response;\n", "});\n", "\n", "const checkpointer = new MemorySaver();\n", "\n", "const workflow = entrypoint({\n", "  name: \"workflow\",\n", "  checkpointer,\n", "}, async (inputs: BaseMessageLike[]) => {\n", "  const previous = getPreviousState<BaseMessage>() ?? [];\n", "  const messages = addMessages(previous, inputs);\n", "  const response = await callModel(messages);\n", "  return entrypoint.final({\n", "    value: response,\n", "    save: addMessages(messages, response),\n", "  });\n", "});"]}, {"cell_type": "markdown", "id": "250d8fd9-2e7a-4892-9adc-19762a1e3cce", "metadata": {}, "source": ["如果我们尝试使用此工作流程，对话的上下文将在交互过程中保持不变。"]}, {"cell_type": "markdown", "id": "7654ebcc-2179-41b4-92d1-6666f6f8634f", "metadata": {}, "source": ["!!!注释 注释\n", "\n", "如果您使用 LangGraph Cloud 或 LangGraph Studio，则不需要将检查指针传递给 `entrypoint` 包装器，因为它是自动完成的。"]}, {"cell_type": "markdown", "id": "2a1b56c5-bd61-4192-8bdb-458a1e9f0159", "metadata": {}, "source": ["这在实践中是如何运作的："]}, {"cell_type": "code", "execution_count": 3, "id": "cfd140f0-a5a6-4697-8115-322242f197b5", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["============================== ai message ==============================\n", "Hi Bob! I'm Claude. Nice to meet you! How can I help you today?\n"]}], "source": ["const config = {\n", "  configurable: { thread_id: \"1\" },\n", "  streamMode: \"values\" as const,\n", "};\n", "const inputMessage = { role: \"user\", content: \"hi! I'm bob\" };\n", "\n", "const stream = await workflow.stream(\n", "  [inputMessage],\n", "  config,\n", ");\n", "\n", "for await (const chunk of stream) {\n", "  console.log(\"=\".repeat(30), `${chunk.getType()} message`, \"=\".repeat(30));\n", "  console.log(chunk.content);\n", "}"]}, {"cell_type": "markdown", "id": "1bb07bf8-68b7-4049-a0f1-eb67a4879a3a", "metadata": {}, "source": ["您始终可以恢复以前的线程："]}, {"cell_type": "code", "execution_count": 4, "id": "08ae8246-11d5-40e1-8567-361e5bef8917", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["============================== ai message ==============================\n", "Your name is Bob - you just told me that in your first message.\n"]}], "source": ["const followupStream = await workflow.stream(\n", "  [{ role: \"user\", content: \"what's my name?\" }], \n", "  config,\n", ");\n", "\n", "for await (const chunk of followupStream) {\n", "  console.log(\"=\".repeat(30), `${chunk.getType()} message`, \"=\".repeat(30));\n", "  console.log(chunk.content);\n", "}"]}, {"cell_type": "markdown", "id": "3f47bbfc-d9ef-4288-ba4a-ebbc0136fa9d", "metadata": {}, "source": ["如果我们想开始一个新的对话，我们可以传入不同的`thread_id`。噗！所有的记忆都消失了！"]}, {"cell_type": "code", "execution_count": 5, "id": "273d56a8-f40f-4a51-a27f-7c6bb2bda0ba", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["============================== ai message ==============================\n", "I don't know your name as we just started chatting. Would you like to introduce yourself?\n"]}], "source": ["const newStream = await workflow.stream(\n", "  [{ role: \"user\", content: \"what's my name?\" }],\n", "  {\n", "    configurable: {\n", "      thread_id: \"2\",\n", "    },\n", "    streamMode: \"values\",\n", "  },\n", ");\n", "\n", "for await (const chunk of newStream) {\n", "  console.log(\"=\".repeat(30), `${chunk.getType()} message`, \"=\".repeat(30));\n", "  console.log(chunk.content);\n", "}"]}, {"cell_type": "markdown", "id": "ac7926a8-4c88-4b16-973c-53d6da3f4a08", "metadata": {}, "source": ["!!!提示“流令牌”\n", "\n", "如果您想从聊天机器人流式传输 LLM 令牌，您可以使用 `streamMode: \"messages\"`。查看此[操作指南](../stream-tokens) 以了解更多信息。"]}], "metadata": {"kernelspec": {"display_name": "TypeScript", "language": "typescript", "name": "tslab"}, "language_info": {"codemirror_mode": {"mode": "typescript", "name": "javascript", "typescript": true}, "file_extension": ".ts", "mimetype": "text/typescript", "name": "typescript", "version": "3.7.2"}}, "nbformat": 4, "nbformat_minor": 5}