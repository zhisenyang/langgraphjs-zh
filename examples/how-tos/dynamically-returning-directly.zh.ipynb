{"cells": [{"cell_type": "markdown", "id": "cd47f365", "metadata": {}, "source": ["# 如何让agent直接返回工具结果\n", "\n", "典型的 ReAct 循环遵循用户 -> 助手 -> 工具 -> 助手 ..., ->\n", "用户。在某些情况下，您不需要在工具完成后调用LLM，\n", "用户可以直接自己查看结果。\n", "\n", "在此示例中，我们将构建一个对话式 ReAct 代理，法学硕士可以在其中\n", "可选择决定返回工具调用的结果作为最终答案。这\n", "当您拥有有时可以生成响应的工具时非常有用\n", "可以接受作为最终答案，并且您希望使用法学硕士来确定\n", "当这种情况时\n", "\n", "## 设置\n", "\n", "首先我们需要安装所需的软件包：\n", "```bash\n", "yarn add @langchain/langgraph @langchain/openai @langchain/core\n", "```\n", "接下来，我们需要为 OpenAI（我们将使用的 LLM）设置 API 密钥。可选地，我们\n", "可以为[LangSmith追踪](https://smith.langchain.com/)设置API密钥，\n", "将为我们提供一流的可观察性。\n"]}, {"cell_type": "code", "execution_count": 1, "id": "bff262dd", "metadata": {"lines_to_next_cell": 2}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Direct Return: LangGraphJS\n"]}], "source": ["// process.env.OPENAI_API_KEY = \"sk_...\";\n", "\n", "// 可选，在 LangSmith 中添加跟踪\n", "// process.env.LANGCHAIN_API_KEY = \"ls__...\"\n", "process.env.LANGCHAIN_CALLBACKS_BACKGROUND = \"true\";\n", "process.env.LANGCHAIN_TRACING_V2 = \"true\";\n", "process.env.LANGCHAIN_PROJECT = \"Direct Return: LangGraphJS\";"]}, {"cell_type": "markdown", "id": "f3c02963", "metadata": {}, "source": ["## 设置工具\n", "\n", "我们将首先定义我们想要使用的工具。对于这个简单的例子，我们将\n", "使用简单的占位符“搜索引擎”。然而，创建起来确实很容易\n", "您自己的工具 - 请参阅文档\n", "[此处](https://js.langchain.com/docs/modules/agents/tools/dynamic)了解如何操作\n", "那。\n", "\n", "要添加“return_direct”选项，我们将创建一个自定义 zod 架构来使用\n", "**而不是**工具自动推断的模式。\n"]}, {"cell_type": "code", "execution_count": 2, "id": "c6e93e06", "metadata": {}, "outputs": [], "source": ["import { DynamicStructuredTool } from \"@langchain/core/tools\";\n", "import { z } from \"zod\";\n", "\n", "const SearchTool = z.object({\n", "  query: z.string().describe(\"query to look up online\"),\n", "  // **重要** 我们在这里添加一个 **额外** 字段\n", "  // 该工具不直接使用它 - 它由我们的\n", "  // 来决定是否返回\n", "  // 结果直接呈现给用户\n", "  return_direct: z.boolean()\n", "    .describe(\n", "      \"Whether or not the result of this should be returned directly to the user without you seeing what it is\",\n", "    )\n", "    .default(false),\n", "});\n", "\n", "const searchTool = new DynamicStructuredTool({\n", "  name: \"search\",\n", "  description: \"Call to surf the web.\",\n", "  // 我们在这里重写默认模式\n", "  // 添加额外字段\n", "  schema: SearchTool,\n", "  func: async ({}: { query: string }) => {\n", "    // 这是实际实现的占位符\n", "    // 不过不要让LLM知道这一点😊\n", "    return \"It's sunny in San Francisco, but you better look out if you're a Gemini 😈.\";\n", "  },\n", "});\n", "\n", "const tools = [searchTool];"]}, {"cell_type": "markdown", "id": "f443c375", "metadata": {}, "source": ["我们现在可以将这些工具包装在 `ToolNode` 中。\n", "这是一个预先构建的节点，它接收 LangChain 聊天模型生成的工具调用并调用该工具，\n", "返回输出。"]}, {"cell_type": "code", "execution_count": 3, "id": "82f3a772", "metadata": {"lines_to_next_cell": 2}, "outputs": [], "source": ["import { ToolNode } from \"@langchain/langgraph/prebuilt\";\n", "\n", "const toolNode = new ToolNode(tools);"]}, {"cell_type": "markdown", "id": "e07a9312", "metadata": {}, "source": ["## 设置模型\n", "\n", "现在我们需要加载我们想要使用的聊天模型。\\\n", "重要的是，这应该满足两个标准：\n", "\n", "1.它应该与消息一起使用。我们将以表格形式代表所有代理状态\n", "消息，因此它需要能够与它们很好地配合。\n", "2.应该支持\n", "[工具调用](https://js.langchain.com/docs/concepts/tool_calling/)。\n", "\n", "注意：这些模型要求不是使用 LangGraph 的要求 - 它们\n", "只是这个例子的要求。\n"]}, {"cell_type": "code", "execution_count": 4, "id": "f9263d46", "metadata": {"lines_to_next_cell": 2}, "outputs": [], "source": ["import { ChatOpenAI } from \"@langchain/openai\";\n", "\n", "const model = new ChatOpenAI({\n", "  temperature: 0,\n", "  model: \"gpt-3.5-turbo\",\n", "});\n", "// 这会将工具格式化为模型 API 的 json 架构。\n", "// 然后模型将其用作系统提示符。\n", "const boundModel = model.bindTools(tools);"]}, {"cell_type": "markdown", "id": "4dbab039", "metadata": {}, "source": ["## 定义代理状态\n", "\n", "`langgraph` 中图形的主要类型是\n", "[StateGraph](/langgraphjs/reference/classes/langgraph.StateGraph.html)。\n", "\n", "该图由一个状态对象参数化，该状态对象传递给每个\n", "节点。然后每个节点返回操作来更新该状态。这些操作\n", "可以设置状态的特定属性（例如覆盖现有的\n", "值）或添加到现有属性。是否设置或添加表示在\n", "您构建图表所用的状态对象。\n", "\n", "对于这个例子，我们将跟踪的状态只是一个消息列表。我们\n", "希望每个节点只将消息添加到该列表中。因此，我们将定义\n", "声明如下："]}, {"cell_type": "code", "execution_count": 5, "id": "c85e2d40", "metadata": {"lines_to_next_cell": 2}, "outputs": [], "source": ["import { Annotation } from \"@langchain/langgraph\";\n", "import { BaseMessage } from \"@langchain/core/messages\";\n", "\n", "const AgentState = Annotation.Root({\n", "  messages: Annotation<BaseMessage[]>({\n", "    reducer: (x, y) => x.concat(y),\n", "  }),\n", "});"]}, {"cell_type": "markdown", "id": "fc4b9760", "metadata": {}, "source": ["## 定义节点\n", "\n", "我们现在需要在图中定义一些不同的节点。在`langgraph`中，一个节点\n", "可以是一个函数或一个\n", "[可运行](https://js.langchain.com/docs/expression_language/)。有两个\n", "为此我们需要的主要节点：\n", "\n", "1. 代理：负责决定采取什么（如果有）行动。\n", "2. 调用工具的函数：如果代理决定采取行动，该节点\n", "然后将执行该操作。\n", "\n", "我们还需要定义一些边。其中一些边缘可能是有条件的。\n", "它们是有条件的原因是基于节点的输出，其中之一\n", "可以采取多条路径。直到该节点才知道所采取的路径\n", "运行（LLM 决定）。\n", "\n", "1. 条件边缘：调用代理后，我们应该：如果\n", "代理说要采取行动，那么调用工具的函数应该是\n", "称为 b.如果代理说已经完成，那么就应该完成\n", "2. 正常边缘：调用工具后，应始终返回到\n", "代理决定下一步做什么\n", "\n", "让我们定义节点以及一个函数来决定什么条件\n", "边取。\n"]}, {"cell_type": "code", "execution_count": 6, "id": "c3da4bde", "metadata": {"lines_to_next_cell": 2}, "outputs": [], "source": ["import { RunnableConfig } from \"@langchain/core/runnables\";\n", "import { END } from \"@langchain/langgraph\";\n", "import { AIMessage } from \"@langchain/core/messages\";\n", "\n", "// 定义判断是否继续的函数\n", "const shouldContinue = (state: typeof AgentState.State) => {\n", "  const { messages } = state;\n", "  const lastMessage = messages[messages.length - 1] as AIMessage;\n", "  // 如果没有函数调用，那么我们就完成了\n", "  if (!lastMessage?.tool_calls?.length) {\n", "    return END;\n", "  } // Otherwise if there is, we check if it's suppose to return direct\n", "  else {\n", "    const args = lastMessage.tool_calls[0].args;\n", "    if (args?.return_direct) {\n", "      return \"final\";\n", "    } else {\n", "      return \"tools\";\n", "    }\n", "  }\n", "};\n", "\n", "// 定义调用模型的函数\n", "const callModel = async (state: typeof AgentState.State, config?: RunnableConfig) => {\n", "  const messages = state.messages;\n", "  const response = await boundModel.invoke(messages, config);\n", "  // 我们返回一个对象，因为这将被添加到现有列表中\n", "  return { messages: [response] };\n", "};"]}, {"cell_type": "markdown", "id": "cbd38eae", "metadata": {}, "source": ["## 定义图表\n", "\n", "我们现在可以将它们放在一起并定义图表！\n"]}, {"cell_type": "code", "execution_count": 7, "id": "7f830fef", "metadata": {}, "outputs": [], "source": ["import { START, StateGraph } from \"@langchain/langgraph\";\n", "\n", "// 定义一个新图\n", "const workflow = new StateGraph(AgentState)\n", "  // 定义我们将在其之间循环的两个节点\n", "  .addNode(\"agent\", callModel)\n", "  // 请注意，“操作”和“最终”节点是相同的！\n", "  .addNode(\"tools\", toolNode)\n", "  .addNode(\"final\", toolNode)\n", "  // 将入口点设置为“agent”\n", "  .addEdge(START, \"agent\")\n", "  // 我们现在添加一个条件边\n", "  .addConditionalEdges(\n", "    // 首先，我们定义起始节点。我们使用“代理”。\n", "    \"agent\",\n", "    // 接下来，我们传入将确定接下来调用哪个节点的函数。\n", "    shouldContinue,\n", "  )\n", "  // 我们现在添加从“tools”到“agent”的正常边缘。\n", "  .addEdge(\"tools\", \"agent\")\n", "  .addEdge(\"final\", END);\n", "\n", "// 最后，我们编译它！\n", "const app = workflow.compile();"]}, {"cell_type": "markdown", "id": "ac83bfea", "metadata": {}, "source": ["## 使用它！\n", "\n", "我们现在可以使用它了！现在这暴露了\n", "[相同的界面](https://js.langchain.com/docs/expression_language/) 与所有\n", "其他 LangChain 运行程序。\n"]}, {"cell_type": "code", "execution_count": 8, "id": "9ba5e47a", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["[human]: what is the weather in sf\n", "-----\n", "\n", "[ai]:  \n", "Tools: \n", "- search({\"query\":\"weather in San Francisco\"})\n", "-----\n", "\n", "[tool]: It's sunny in San Francisco, but you better look out if you're a Gemini 😈.\n", "-----\n", "\n", "[ai]: The weather in San Francisco is sunny.\n", "-----\n", "\n"]}], "source": ["import { HumanMessage, isAIMessage } from \"@langchain/core/messages\";\n", "\n", "const prettyPrint = (message: BaseMessage) => {\n", "  let txt = `[${message._getType()}]: ${message.content}`;\n", "  if (\n", "    isAIMessage(message) && (message as AIMessage)?.tool_calls?.length || 0 > 0\n", "  ) {\n", "    const tool_calls = (message as AIMessage)?.tool_calls\n", "      ?.map((tc) => `- ${tc.name}(${JSON.stringify(tc.args)})`)\n", "      .join(\"\\n\");\n", "    txt += ` \\nTools: \\n${tool_calls}`;\n", "  }\n", "  console.log(txt);\n", "};\n", "\n", "const inputs = { messages: [new HumanMessage(\"what is the weather in sf\")] };\n", "for await (const output of await app.stream(inputs, { streamMode: \"values\" })) {\n", "  const lastMessage = output.messages[output.messages.length - 1];\n", "  prettyPrint(lastMessage);\n", "  console.log(\"-----\\n\");\n", "}"]}, {"cell_type": "code", "execution_count": 9, "id": "779e0d88", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["[human]: what is the weather in sf? return this result directly by setting return_direct = True\n", "-----\n", "\n", "[ai]:  \n", "Tools: \n", "- search({\"query\":\"weather in San Francisco\",\"return_direct\":true})\n", "-----\n", "\n", "[tool]: It's sunny in San Francisco, but you better look out if you're a Gemini 😈.\n", "-----\n", "\n"]}], "source": ["const inputs2 = {\n", "  messages: [\n", "    new HumanMessage(\n", "      \"what is the weather in sf? return this result directly by setting return_direct = True\",\n", "    ),\n", "  ],\n", "};\n", "for await (\n", "  const output of await app.stream(inputs2, { streamMode: \"values\" })\n", ") {\n", "  const lastMessage = output.messages[output.messages.length - 1];\n", "  prettyPrint(lastMessage);\n", "  console.log(\"-----\\n\");\n", "}"]}, {"cell_type": "markdown", "id": "f99d8e3b", "metadata": {}, "source": ["完毕！运行 `tools` 节点后图表 **停止**！\n", "```\n", "```"]}], "metadata": {"jupytext": {"encoding": "# -*- coding: utf-8 -*-"}, "kernelspec": {"display_name": "TypeScript", "language": "typescript", "name": "tslab"}, "language_info": {"codemirror_mode": {"mode": "typescript", "name": "javascript", "typescript": true}, "file_extension": ".ts", "mimetype": "text/typescript", "name": "typescript", "version": "3.7.2"}}, "nbformat": 4, "nbformat_minor": 5}