{"cells": [{"cell_type": "markdown", "id": "38a67792", "metadata": {}, "source": ["# 如何管理代理步骤\n", "\n", "在此示例中，我们将构建一个显式管理中间过程的 ReAct Agent\n", "步骤。\n", "\n", "前面的示例只是将所有消息放入模型中，但是额外的\n", "上下文可能会分散代理的注意力并增加 API 调用的延迟。在这个例子中\n", "我们只会在聊天历史记录中包含 `N` 最近的消息。注意\n", "这是为了说明一般的国家管理。\n", "\n", "## 设置\n", "\n", "首先我们需要安装所需的包：\n", "```bash\n", "yarn add @langchain/langgraph @langchain/openai @langchain/core\n", "```\n", "接下来，我们需要为 Anthropic（我们将使用的 LLM）设置 API 密钥。"]}, {"cell_type": "code", "execution_count": 1, "id": "36033b66", "metadata": {}, "outputs": [], "source": ["// process.env.OPENAI_API_KEY = \"sk_...\";"]}, {"cell_type": "markdown", "id": "e98d96da", "metadata": {}, "source": ["或者，我们可以设置 API 密钥\n", "[LangSmith 追踪](https://smith.langchain.com/)，这将为我们提供\n", "一流的可观测性。"]}, {"cell_type": "code", "execution_count": 2, "id": "38934fde", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Managing Agent Steps: LangGraphJS\n"]}], "source": ["// 可选，在 LangSmith 中添加跟踪\n", "// process.env.LANGCHAIN_API_KEY = \"ls__...\";\n", "process.env.LANGCHAIN_CALLBACKS_BACKGROUND = \"true\";\n", "process.env.LANGCHAIN_TRACING_V2 = \"true\";\n", "process.env.LANGCHAIN_PROJECT = \"Managing Agent Steps: LangGraphJS\";"]}, {"cell_type": "markdown", "id": "8aeecba6", "metadata": {}, "source": ["## 设置状态\n", "\n", "`langgraph` 中图形的主要类型是\n", "[StateGraph](/langgraphjs/reference/classes/langgraph.StateGraph.html)。\n", "该图由一个状态对象参数化，该状态对象传递给每个\n", "节点。然后每个节点返回操作来更新该状态。这些操作\n", "可以设置状态的特定属性（例如覆盖现有的\n", "值）或添加到现有属性。是否设置或添加表示在\n", "您构建图表所用的状态对象。\n", "\n", "对于这个例子，我们将跟踪的状态只是一个消息列表。我们\n", "希望每个节点只将消息添加到该列表中。因此，我们将定义\n", "声明如下："]}, {"cell_type": "code", "execution_count": 3, "id": "e95ef6be", "metadata": {}, "outputs": [], "source": ["import { Annotation } from \"@langchain/langgraph\";\n", "import { BaseMessage } from \"@langchain/core/messages\";\n", "\n", "const AgentState = Annotation.Root({\n", "  messages: Annotation<BaseMessage[]>({\n", "    reducer: (x, y) => x.concat(y),\n", "  }),\n", "});"]}, {"cell_type": "markdown", "id": "d6954509", "metadata": {}, "source": ["## 设置工具\n", "\n", "我们将首先定义我们想要使用的工具。对于这个简单的例子，我们将\n", "创建一个占位符搜索引擎。创建自己的工具真的很容易 -\n", "查看文档\n", "[此处](https://js.langchain.com/docs/modules/agents/tools/dynamic)了解如何操作\n", "那。"]}, {"cell_type": "code", "execution_count": 4, "id": "ec9f73a5", "metadata": {}, "outputs": [], "source": ["import { DynamicStructuredTool } from \"@langchain/core/tools\";\n", "import { z } from \"zod\";\n", "\n", "const searchTool = new DynamicStructuredTool({\n", "  name: \"search\",\n", "  description: \"Call to surf the web.\",\n", "  schema: z.object({\n", "    query: z.string().describe(\"The query to use in your search.\"),\n", "  }),\n", "  func: async ({}: { query: string }) => {\n", "    // 这是一个占位符，但不要告诉法学硕士......\n", "    return \"Try again in a few seconds! Checking with the weathermen... Call be again next.\";\n", "  },\n", "});\n", "\n", "const tools = [searchTool];"]}, {"cell_type": "markdown", "id": "e8669db6", "metadata": {}, "source": ["我们现在可以将这些工具包装在一个简单的\n", "[ToolNode](/langgraphjs/reference/classes/langgraph_prebuilt.ToolNode.html).\\\n", "这是一个简单的类，它接收包含消息的消息列表\n", "[带有 tool_calls 的 AIMessages](https://v02.api.js.langchain.com/classes/langchain_core_messages_ai.AIMessage.html),\n", "运行工具，并将输出返回为\n", "[ToolMessage](https://v02.api.js.langchain.com/classes/langchain_core_messages_tool.ToolMessage.html)。"]}, {"cell_type": "code", "execution_count": 5, "id": "7f4829c3", "metadata": {}, "outputs": [], "source": ["import { ToolNode } from \"@langchain/langgraph/prebuilt\";\n", "\n", "const toolNode = new ToolNode<typeof AgentState.State>(tools);"]}, {"cell_type": "markdown", "id": "81a0a750", "metadata": {}, "source": ["## 设置模型\n", "\n", "现在我们需要加载我们想要使用的聊天模型。这应该满足两个\n", "标准：\n", "\n", "1.它应该与消息一起使用，因为我们的状态主要是消息列表\n", "（聊天记录）。\n", "2.它应该与工具调用一起使用，因为我们使用的是预构建的\n", "[工具节点](/langgraphjs/reference/classes/langgraph_prebuilt.ToolNode.html)\n", "\n", "**注意：** 这些模型要求不是使用 LangGraph 的要求 -\n", "它们只是这个特定示例的要求。"]}, {"cell_type": "code", "execution_count": 6, "id": "cf1fcc3f", "metadata": {}, "outputs": [], "source": ["import { ChatOpenAI } from \"@langchain/openai\";\n", "\n", "const model = new ChatOpenAI({\n", "  model: \"gpt-4o\",\n", "  temperature: 0,\n", "});"]}, {"cell_type": "code", "execution_count": 7, "id": "a0903bb8", "metadata": {}, "outputs": [], "source": ["// 完成此操作后，我们应该确保模型知道它可以调用这些工具。\n", "// 我们可以通过将工具绑定到模型类来做到这一点。\n", "const boundModel = model.bindTools(tools);"]}, {"cell_type": "markdown", "id": "c96f67f3", "metadata": {}, "source": ["## 定义节点\n", "\n", "我们现在需要在图中定义一些不同的节点。在`langgraph`中，一个节点\n", "可以是一个函数或一个\n", "[可运行](https://js.langchain.com/docs/expression_language/)。有两个\n", "为此我们需要的主要节点：\n", "\n", "1. 代理：负责决定采取什么（如果有）行动。\n", "2. 调用工具的函数：如果代理决定采取行动，该节点\n", "然后将执行该操作。\n", "\n", "我们还需要定义一些边。其中一些边缘可能是有条件的。\n", "它们是有条件的原因是基于节点的输出，其中之一\n", "可以采取多条路径。直到该节点才知道所采取的路径\n", "运行（LLM 决定）。\n", "\n", "1. 条件边缘：调用代理后，我们应该：如果\n", "代理说要采取行动，那么调用工具的函数应该是\n", "称为\\\n", "b.如果代理说已经完成，那么就应该完成\n", "2. 正常边缘：调用工具后，应始终返回到\n", "代理决定下一步做什么\n", "\n", "让我们定义节点以及一个函数来决定什么条件\n", "边取。"]}, {"cell_type": "code", "execution_count": 8, "id": "1249b1b3", "metadata": {}, "outputs": [], "source": ["import { END } from \"@langchain/langgraph\";\n", "import { AIMessage, ToolMessage } from \"@langchain/core/messages\";\n", "import { RunnableConfig } from \"@langchain/core/runnables\";\n", "\n", "// 定义判断是否继续的函数\n", "const shouldContinue = (state: typeof AgentState.State) => {\n", "  const { messages } = state;\n", "  const lastMessage = messages[messages.length - 1] as AIMessage;\n", "  // 如果没有函数调用，那么我们就完成了\n", "  if (!lastMessage.tool_calls || lastMessage.tool_calls.length === 0) {\n", "    return END;\n", "  }\n", "  // 否则，如果有，我们继续\n", "  return \"tools\";\n", "};\n", "\n", "// **修改**\n", "//\n", "// 在这里，我们不会将所有消息传递给模型，而是仅传递最近的“N”消息。请注意，这是一种非常简单的处理消息的方法，仅供参考，根据您的用例，您可能还需要研究其他方法。我们还必须确保不会截断聊天历史记录以首先包含工具消息，因为这会导致 API 错误。\n", "const callModel = async (\n", "  state: typeof AgentState.State,\n", "  config?: RunnableConfig,\n", ") => {\n", "  let modelMessages = [];\n", "  for (let i = state.messages.length - 1; i >= 0; i--) {\n", "    modelMessages.push(state.messages[i]);\n", "    if (modelMessages.length >= 5) {\n", "      if (!ToolMessage.isInstance(modelMessages[modelMessages.length - 1])) {\n", "        break;\n", "      }\n", "    }\n", "  }\n", "  modelMessages.reverse();\n", "\n", "  const response = await boundModel.invoke(modelMessages, config);\n", "  // 我们返回一个对象，因为这将被添加到现有列表中\n", "  return { messages: [response] };\n", "};"]}, {"cell_type": "markdown", "id": "227a5040", "metadata": {}, "source": ["## 定义图表\n", "\n", "我们现在可以将它们放在一起并定义图表！"]}, {"cell_type": "code", "execution_count": 9, "id": "ff5f7b65", "metadata": {}, "outputs": [], "source": ["import { START, StateGraph } from \"@langchain/langgraph\";\n", "\n", "// 定义一个新图\n", "const workflow = new StateGraph(AgentState)\n", "  .addNode(\"agent\", callModel)\n", "  .addNode(\"tools\", toolNode)\n", "  .addEdge(START, \"agent\")\n", "  .addConditionalEdges(\n", "    \"agent\",\n", "    shouldContinue,\n", "  )\n", "  .addEdge(\"tools\", \"agent\");\n", "\n", "// 最后，我们编译它！\n", "// 这会将其编译成 LangChain Runnable，\n", "// 这意味着您可以像使用任何其他可运行程序一样使用它\n", "const app = workflow.compile();"]}, {"cell_type": "markdown", "id": "6049db62", "metadata": {}, "source": ["## 使用它！\n", "\n", "我们现在可以使用它了！现在这暴露了\n", "[相同的界面](https://js.langchain.com/docs/expression_language/) 与所有\n", "其他 LangChain 运行程序。"]}, {"cell_type": "code", "execution_count": 10, "id": "7bd7315e", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["[human]: what is the weather in sf? Don't give up! Keep using your tools.\n", "-----\n", "\n", "[ai]:  \n", "Tools: \n", "- search({\"query\":\"current weather in San Francisco\"})\n", "-----\n", "\n", "[tool]: Try again in a few seconds! Checking with the weathermen... Call be again next.\n", "-----\n", "\n", "[ai]:  \n", "Tools: \n", "- search({\"query\":\"current weather in San Francisco\"})\n", "-----\n", "\n", "[tool]: Try again in a few seconds! Checking with the weathermen... Call be again next.\n", "-----\n", "\n", "[ai]:  \n", "Tools: \n", "- search({\"query\":\"current weather in San Francisco\"})\n", "-----\n", "\n", "[tool]: Try again in a few seconds! Checking with the weathermen... Call be again next.\n", "-----\n", "\n", "[ai]:  \n", "Tools: \n", "- search({\"query\":\"current weather in San Francisco\"})\n", "-----\n", "\n", "[tool]: Try again in a few seconds! Checking with the weathermen... Call be again next.\n", "-----\n", "\n", "[ai]:  \n", "Tools: \n", "- search({\"query\":\"current weather in San Francisco\"})\n", "-----\n", "\n", "As expected, maximum steps reached. Exiting.\n"]}], "source": ["import { HumanMessage, isAIMessage } from \"@langchain/core/messages\";\n", "import { GraphRecursionError } from \"@langchain/langgraph\";\n", "\n", "const prettyPrint = (message: BaseMessage) => {\n", "  let txt = `[${message._getType()}]: ${message.content}`;\n", "  if (\n", "    (isAIMessage(message) && (message as AIMessage)?.tool_calls?.length) ||\n", "    0 > 0\n", "  ) {\n", "    const tool_calls = (message as AIMessage)?.tool_calls\n", "      ?.map((tc) => `- ${tc.name}(${JSON.stringify(tc.args)})`)\n", "      .join(\"\\n\");\n", "    txt += ` \\nTools: \\n${tool_calls}`;\n", "  }\n", "  console.log(txt);\n", "};\n", "\n", "const inputs = {\n", "  messages: [\n", "    new HumanMessage(\n", "      \"what is the weather in sf? Don't give up! Keep using your tools.\",\n", "    ),\n", "  ],\n", "};\n", "// 设置 recursionLimit 将设置最大步数。我们希望这会无限循环:)\n", "try {\n", "  for await (\n", "    const output of await app.stream(inputs, {\n", "      streamMode: \"values\",\n", "      recursionLimit: 10,\n", "    })\n", "  ) {\n", "    const lastMessage = output.messages[output.messages.length - 1];\n", "    prettyPrint(lastMessage);\n", "    console.log(\"-----\\n\");\n", "  }\n", "} catch (e) {\n", "  // 由于我们正在截断聊天记录，代理永远没有机会\n", "  // 看到足够的信息来知道停止，所以它会一直循环，直到我们点击\n", "  // 最大递归限制。\n", "  if ((e as GraphRecursionError).name === \"GraphRecursionError\") {\n", "    console.log(\"As expected, maximum steps reached. Exiting.\");\n", "  } else {\n", "    console.error(e);\n", "  }\n", "}"]}], "metadata": {"kernelspec": {"display_name": "TypeScript", "language": "typescript", "name": "tslab"}, "language_info": {"codemirror_mode": {"mode": "typescript", "name": "javascript", "typescript": true}, "file_extension": ".ts", "mimetype": "text/typescript", "name": "typescript", "version": "3.7.2"}}, "nbformat": 4, "nbformat_minor": 5}