{"cells": [{"cell_type": "markdown", "id": "51466c8d-8ce4-4b3d-be4e-18fdbeda5f53", "metadata": {}, "source": ["# 聊天代理执行者\n", "\n", "在此示例中，我们将构建一个聊天执行器，该执行器使用以下函数调用\n", "划痕。"]}, {"cell_type": "markdown", "id": "7cbd446a-808f-4394-be92-d45ab818953c", "metadata": {}, "source": ["## 设置¶\n", "\n", "首先我们需要安装需要的包\n", "```bash\n", "yarn add langchain @langchain/openai @langchain/langgraph\n", "```"]}, {"cell_type": "markdown", "id": "0abe11f4-62ed-4dc4-8875-3db21e260d1d", "metadata": {}, "source": ["接下来，我们需要为 OpenAI（我们将使用的 LLM）和 Tavily（我们将使用的 LLM）设置 API 密钥\n", "我们将使用的搜索工具）\n", "```bash\n", "export OPENAI_API_KEY=\n", "export TAVILY_API_KEY=\n", "```"]}, {"cell_type": "markdown", "id": "f0ed46a8-effe-4596-b0e1-a6a29ee16f5c", "metadata": {}, "source": ["或者，我们可以设置 API 密钥\n", "[LangSmith 追踪](https://smith.langchain.com/)，这将为我们提供\n", "一流的可观测性。\n", "```bash\n", "export LANGCHAIN_TRACING_V2=true\n", "export LANGCHAIN_API_KEY=\n", "```"]}, {"cell_type": "markdown", "id": "21ac643b-cb06-4724-a80c-2862ba4773f1", "metadata": {}, "source": ["## 设置工具\n", "\n", "我们将首先定义我们想要使用的工具。对于这个简单的示例，我们将通过 Tavily 使用内置搜索工具。然而，创建自己的工具确实很容易 - 请参阅[此处](https://js.langchain.com/docs/how_to/custom_tools/)文档了解如何做到这一点。\n", "\n", "定义我们的工具后，我们可以将它们包装在一个简单的 `ToolExecutor` 中。这是一个真正简单的\n", "类接受 `ToolInvocation` 并调用该工具，返回输出。\n", "\n", "ToolIncation 是具有 `tool` 和 `toolInput` 属性的任何类型。"]}, {"cell_type": "code", "execution_count": null, "id": "5cf3331e-ccb3-41c8-aeb9-a840a94d41e7", "metadata": {}, "outputs": [], "source": ["import { ToolExecutor } from \"@langchain/langgraph/prebuilt\";\n", "import { TavilySearch } from \"@langchain/tavily\";\n", "\n", "const tools = [new TavilySearch({ maxResults: 1 })];\n", "\n", "const toolExecutor = new ToolExecutor({\n", "  tools,\n", "});"]}, {"cell_type": "markdown", "id": "5497ed70-fce3-47f1-9cad-46f912bad6a5", "metadata": {}, "source": ["## 设置模型\n", "\n", "现在我们需要加载我们想要使用的聊天模型。重要的是，这应该\n", "满足两个条件：\n", "\n", "1.它应该与消息一起使用。我们将以表格形式代表所有代理状态\n", "消息，因此它需要能够与它们很好地配合。\n", "2. 需要配合OpenAI函数调用。这意味着它应该是\n", "OpenAI 模型或公开类似接口的模型。\n", "\n", "注意：这些模型要求不是使用 LangGraph 的要求 - 它们\n", "只是这个例子的要求。"]}, {"cell_type": "code", "execution_count": 5, "id": "892b54b9-75f0-4804-9ed0-88b5e5532989", "metadata": {}, "outputs": [], "source": ["import { ChatOpenAI } from \"@langchain/openai\";\n", "\n", "// 我们将设置streaming=True，以便我们可以流式传输令牌\n", "// 有关详细信息，请参阅流媒体部分。\n", "const model = new ChatOpenAI({\n", "  temperature: 0,\n", "  streaming: true,\n", "});"]}, {"cell_type": "markdown", "id": "a77995c0-bae2-4cee-a036-8688a90f05b9", "metadata": {}, "source": ["完成此操作后，我们应该确保模型知道它具有这些\n", "可供调用的工具。我们可以通过将 LangChain 工具转换为\n", "OpenAI函数调用的格式，然后将它们绑定到模型类。"]}, {"cell_type": "code", "execution_count": 6, "id": "cd3cbae5-d92c-4559-a4aa-44721b80d107", "metadata": {}, "outputs": [], "source": ["import { convertToOpenAIFunction } from \"@langchain/core/utils/function_calling\";\n", "\n", "const toolsAsOpenAIFunctions = tools.map((tool) =>\n", "  convertToOpenAIFunction(tool)\n", ");\n", "const newModel = model.bind({\n", "  functions: toolsAsOpenAIFunctions,\n", "});"]}, {"cell_type": "markdown", "id": "8e8b9211-93d0-4ad5-aa7a-9c09099c53ff", "metadata": {}, "source": ["### 定义代理状态\n", "\n", "`langgraph` 中图形的主要类型是 `StatefulGraph`。该图是\n", "由传递到每个节点的状态对象参数化。每个节点\n", "然后返回更新该状态的操作。这些操作可以设置\n", "状态的特定属性（例如覆盖现有值）或添加到\n", "现有的属性。通过注释状态来表示是设置还是添加\n", "您构建图表所用的对象。\n", "\n", "对于这个例子，我们将跟踪的状态只是一个消息列表。我们\n", "希望每个节点只将消息添加到该列表中。为此，我们通过 `Annotation` 函数定义我们的状态，其中单个属性 `messages` 是 `BaseMessage` 的列表。我们的属性 `messages` 的值是另一个 `Annotation`，它有两个子属性：`reducer` 和 `default`。`reducer` 键必须是一个返回函数的工厂，该函数接受属性的当前值和要添加的新值，并返回属性的新值。"]}, {"cell_type": "code", "execution_count": 11, "id": "ea793afa-2eab-4901-910d-6eed90cd6564", "metadata": {}, "outputs": [], "source": ["import { BaseMessage } from \"@langchain/core/messages\";\n", "import { Annotation } from \"@langchain/langgraph\";\n", "\n", "const AgentState = Annotation.Root({\n", "  messages: Annotation<BaseMessage[]>({\n", "    reducer: (x, y) => x.concat(y),\n", "  })\n", "})"]}, {"cell_type": "markdown", "id": "e03c5094-9297-4d19-a04e-3eedc75cefb4", "metadata": {}, "source": ["## 定义节点\n", "\n", "我们现在需要在图中定义一些不同的节点。在`langgraph`中，一个节点\n", "可以是一个函数或一个\n", "[可运行](https://js.langchain.com/docs/expression_language/)。有两个\n", "为此我们需要的主要节点：\n", "\n", "1. 代理：负责决定采取什么（如果有）行动。\n", "2. 调用工具的函数：如果代理决定采取行动，该节点\n", "然后将执行该操作。\n", "\n", "我们还需要定义一些边。其中一些边缘可能是有条件的。\n", "它们是有条件的原因是基于节点的输出，其中之一\n", "可以采取多条路径。直到该节点才知道所采取的路径\n", "运行（LLM 决定）。\n", "\n", "1. 条件边缘：调用代理后，我们应该：如果\n", "代理说要采取行动，那么调用工具的函数应该是\n", "称为 b.如果代理说已经完成，那么就应该完成\n", "2. 正常边缘：调用工具后，应始终返回到\n", "代理决定下一步做什么\n", "\n", "让我们定义节点以及一个函数来决定什么条件\n", "边取。"]}, {"cell_type": "code", "execution_count": 12, "id": "3b541bb9-900c-40d0-964d-7b5dfee30667", "metadata": {}, "outputs": [], "source": ["import { FunctionMessage } from \"@langchain/core/messages\";\n", "import { AgentAction } from \"@langchain/core/agents\";\n", "\n", "// 定义判断是否继续的函数\n", "const shouldContinue = (state: typeof AgentState.State) => {\n", "  const { messages } = state;\n", "  const lastMessage = messages[messages.length - 1];\n", "  // 如果没有函数调用，那么我们就完成了\n", "  if (\n", "    !(\"function_call\" in lastMessage.additional_kwargs) ||\n", "    !lastMessage.additional_kwargs.function_call\n", "  ) {\n", "    return \"end\";\n", "  }\n", "  // 否则，如果有，我们继续\n", "  return \"continue\";\n", "};\n", "\n", "// 定义执行工具的函数\n", "const _getAction = (state: typeof AgentState.State): AgentAction => {\n", "  const { messages } = state;\n", "  // 基于继续条件\n", "  // 我们知道最后一条消息涉及函数调用\n", "  const lastMessage = messages[messages.length - 1];\n", "  if (!lastMessage) {\n", "    throw new Error(\"No messages found.\");\n", "  }\n", "  if (!lastMessage.additional_kwargs.function_call) {\n", "    throw new Error(\"No function call found in message.\");\n", "  }\n", "  // 我们从 function_call 构造一个 AgentAction\n", "  return {\n", "    tool: lastMessage.additional_kwargs.function_call.name,\n", "    toolInput: JSON.stringify(\n", "      lastMessage.additional_kwargs.function_call.arguments,\n", "    ),\n", "    log: \"\",\n", "  };\n", "};\n", "\n", "// 定义调用模型的函数\n", "const callModel = async (state: typeof AgentState.State) => {\n", "  const { messages } = state;\n", "  const response = await newModel.invoke(messages);\n", "  // 我们返回一个列表，因为这将被添加到现有列表中\n", "  return {\n", "    messages: [response],\n", "  };\n", "};\n", "\n", "const callTool = async (state: typeof AgentState.State) => {\n", "  const action = _getAction(state);\n", "  // 我们调用 tool_executor 并得到响应\n", "  const response = await toolExecutor.invoke(action);\n", "  // 我们使用响应来创建 FunctionMessage\n", "  const functionMessage = new FunctionMessage({\n", "    content: response,\n", "    name: action.tool,\n", "  });\n", "  // 我们返回一个列表，因为这将被添加到现有列表中\n", "  return { messages: [functionMessage] };\n", "};"]}, {"cell_type": "markdown", "id": "ffd6e892-946c-4899-8cc0-7c9291c1f73b", "metadata": {}, "source": ["## 定义图表\n", "\n", "我们现在可以将它们放在一起并定义图表！"]}, {"cell_type": "code", "execution_count": 13, "id": "813ae66c-3b58-4283-a02a-36da72a2ab90", "metadata": {}, "outputs": [], "source": ["import { END, START, StateGraph } from \"@langchain/langgraph\";\n", "\n", "// 定义一个新图\n", "const workflow = new StateGraph(AgentState)\n", "  // 定义我们将在其之间循环的两个节点\n", "  .addNode(\"agent\", callModel)\n", "  .addNode(\"action\", callTool)\n", "  // 将入口点设置为“agent”\n", "  // 这意味着该节点是第一个被调用的节点\n", "  .addEdge(START, \"agent\")\n", "  // 我们现在添加一个条件边\n", "  .addConditionalEdges(\n", "    // 首先，我们定义起始节点。我们使用“代理”。\n", "    // 这意味着这些是调用“agent”节点后获取的边。\n", "    \"agent\",\n", "    // 接下来，我们传入将确定接下来调用哪个节点的函数。\n", "    shouldContinue,\n", "    // 最后我们传入一个映射。\n", "    // 键是字符串，值是其他节点。\n", "    // END 是一个特殊的节点，标记图形应该结束。\n", "    // 将会发生的事情是我们将调用“should_continue”，然后该输出\n", "    // 将与此映射中的键进行匹配。\n", "    // 根据匹配的节点，将调用该节点。\n", "    {\n", "      // 如果是“tools”，那么我们称之为工具节点。\n", "      continue: \"action\",\n", "      // 否则我们就结束了。\n", "      end: END,\n", "    },\n", "  )\n", "  // 我们现在添加从“tools”到“agent”的正常边缘。\n", "  // 这意味着在调用“tools”之后，接下来调用“agent”节点。\n", "  .addEdge(\"action\", \"agent\");\n", "\n", "// 最后，我们编译它！\n", "// 这会将其编译成 LangChain Runnable，\n", "// 这意味着您可以像使用任何其他可运行程序一样使用它\n", "const app = workflow.compile();"]}, {"cell_type": "markdown", "id": "547c3931-3dae-4281-ad4e-4b51305594d4", "metadata": {}, "source": ["## 使用它！\n", "\n", "我们现在可以使用它了！现在这暴露了\n", "[相同的接口](https://python.langchain.com/docs/expression_language/) 与所有\n", "其他 LangChain 运行程序。"]}, {"cell_type": "code", "execution_count": 14, "id": "8edb04b9-40b6-46f1-a7a8-4b2d8aba7752", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["{\n", "  messages: [\n", "    HumanMessage {\n", "      \"content\": \"what is the weather in sf\",\n", "      \"additional_kwargs\": {},\n", "      \"response_metadata\": {}\n", "    },\n", "    AIMessageChunk {\n", "      \"id\": \"chatcmpl-9y3695OyrZqhRmcbVkioOxXzjXp32\",\n", "      \"content\": \"\",\n", "      \"additional_kwargs\": {\n", "        \"function_call\": {\n", "          \"name\": \"tavily_search_results_json\",\n", "          \"arguments\": \"{\\\"input\\\":\\\"weather in San Francisco\\\"}\"\n", "        }\n", "      },\n", "      \"response_metadata\": {\n", "        \"estimatedTokenUsage\": {\n", "          \"promptTokens\": 80,\n", "          \"completionTokens\": 21,\n", "          \"totalTokens\": 101\n", "        },\n", "        \"prompt\": 0,\n", "        \"completion\": 0,\n", "        \"finish_reason\": \"function_call\",\n", "        \"system_fingerprint\": null\n", "      },\n", "      \"tool_calls\": [],\n", "      \"tool_call_chunks\": [],\n", "      \"invalid_tool_calls\": [],\n", "      \"usage_metadata\": {\n", "        \"input_tokens\": 79,\n", "        \"output_tokens\": 21,\n", "        \"total_tokens\": 100\n", "      }\n", "    },\n", "    FunctionMessage {\n", "      \"content\": \"[{\\\"title\\\":\\\"Weather in San Francisco\\\",\\\"url\\\":\\\"https://www.weatherapi.com/\\\",\\\"content\\\":\\\"{'location': {'name': 'San Francisco', 'region': 'California', 'country': 'United States of America', 'lat': 37.78, 'lon': -122.42, 'tz_id': 'America/Los_Angeles', 'localtime_epoch': 1724098493, 'localtime': '2024-08-19 13:14'}, 'current': {'last_updated_epoch': 1724097600, 'last_updated': '2024-08-19 13:00', 'temp_c': 21.1, 'temp_f': 70.0, 'is_day': 1, 'condition': {'text': 'Sunny', 'icon': '//cdn.weatherapi.com/weather/64x64/day/113.png', 'code': 1000}, 'wind_mph': 9.4, 'wind_kph': 15.1, 'wind_degree': 250, 'wind_dir': 'WSW', 'pressure_mb': 1019.0, 'pressure_in': 30.08, 'precip_mm': 0.0, 'precip_in': 0.0, 'humidity': 64, 'cloud': 0, 'feelslike_c': 21.1, 'feelslike_f': 70.0, 'windchill_c': 17.7, 'windchill_f': 63.8, 'heatindex_c': 17.7, 'heatindex_f': 63.8, 'dewpoint_c': 10.7, 'dewpoint_f': 51.2, 'vis_km': 16.0, 'vis_miles': 9.0, 'uv': 5.0, 'gust_mph': 13.2, 'gust_kph': 21.2}}\\\",\\\"score\\\":0.9991679,\\\"raw_content\\\":null}]\",\n", "      \"name\": \"tavily_search_results_json\",\n", "      \"additional_kwargs\": {},\n", "      \"response_metadata\": {}\n", "    },\n", "    AIMessageChunk {\n", "      \"id\": \"chatcmpl-9y36FtclcqetcawFZmYH7rDvajQ7A\",\n", "      \"content\": \"The current weather in San Francisco is sunny with a temperature of 70.0°F (21.1°C). The wind is blowing at 15.1 kph from the WSW direction. The humidity is at 64%, and there is no precipitation.\",\n", "      \"additional_kwargs\": {},\n", "      \"response_metadata\": {\n", "        \"estimatedTokenUsage\": {\n", "          \"promptTokens\": 536,\n", "          \"completionTokens\": 53,\n", "          \"totalTokens\": 589\n", "        },\n", "        \"prompt\": 0,\n", "        \"completion\": 0,\n", "        \"finish_reason\": \"stop\",\n", "        \"system_fingerprint\": null\n", "      },\n", "      \"tool_calls\": [],\n", "      \"tool_call_chunks\": [],\n", "      \"invalid_tool_calls\": [],\n", "      \"usage_metadata\": {\n", "        \"input_tokens\": 538,\n", "        \"output_tokens\": 54,\n", "        \"total_tokens\": 592\n", "      }\n", "    }\n", "  ]\n", "}\n"]}], "source": ["import { HumanMessage } from \"@langchain/core/messages\";\n", "\n", "const inputs = {\n", "  messages: [new HumanMessage(\"what is the weather in sf\")],\n", "};\n", "await app.invoke(inputs);"]}, {"cell_type": "markdown", "id": "5a9e8155-70c5-4973-912c-dc55104b2acf", "metadata": {}, "source": ["这可能需要一点时间——它在幕后进行了一些调用。为了\n", "为了开始看到一些中间结果，我们可以使用流式处理。\n", "有关详细信息，请参阅下文。\n", "\n", "## 流媒体\n", "\n", "LangGraph 支持多种不同类型的流式传输。\n", "\n", "### 流节点输出\n", "\n", "使用 LangGraph 的好处之一是可以轻松地将输出流式传输为\n", "它是由每个节点产生的。\n", "\n", "在此示例中，我们将重新使用上面的 `inputs` 对象。"]}, {"cell_type": "code", "execution_count": 15, "id": "f544977e-31f7-41f0-88c4-ec9c27b8cecb", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["output {\n", "  agent: {\n", "    messages: [\n", "      AIMessageChunk {\n", "        \"id\": \"chatcmpl-9y36G4P6hDihhZkOCW5T5bJWWNl0Z\",\n", "        \"content\": \"\",\n", "        \"additional_kwargs\": {\n", "          \"function_call\": {\n", "            \"name\": \"tavily_search_results_json\",\n", "            \"arguments\": \"{\\\"input\\\":\\\"weather in San Francisco\\\"}\"\n", "          }\n", "        },\n", "        \"response_metadata\": {\n", "          \"estimatedTokenUsage\": {\n", "            \"promptTokens\": 80,\n", "            \"completionTokens\": 21,\n", "            \"totalTokens\": 101\n", "          },\n", "          \"prompt\": 0,\n", "          \"completion\": 0,\n", "          \"finish_reason\": \"function_call\",\n", "          \"system_fingerprint\": null\n", "        },\n", "        \"tool_calls\": [],\n", "        \"tool_call_chunks\": [],\n", "        \"invalid_tool_calls\": [],\n", "        \"usage_metadata\": {\n", "          \"input_tokens\": 79,\n", "          \"output_tokens\": 21,\n", "          \"total_tokens\": 100\n", "        }\n", "      }\n", "    ]\n", "  }\n", "}\n", "-----\n", "\n", "output {\n", "  action: {\n", "    messages: [\n", "      FunctionMessage {\n", "        \"content\": \"[{\\\"title\\\":\\\"Weather in San Francisco\\\",\\\"url\\\":\\\"https://www.weatherapi.com/\\\",\\\"content\\\":\\\"{'location': {'name': 'San Francisco', 'region': 'California', 'country': 'United States of America', 'lat': 37.78, 'lon': -122.42, 'tz_id': 'America/Los_Angeles', 'localtime_epoch': 1724098493, 'localtime': '2024-08-19 13:14'}, 'current': {'last_updated_epoch': 1724097600, 'last_updated': '2024-08-19 13:00', 'temp_c': 21.1, 'temp_f': 70.0, 'is_day': 1, 'condition': {'text': 'Sunny', 'icon': '//cdn.weatherapi.com/weather/64x64/day/113.png', 'code': 1000}, 'wind_mph': 9.4, 'wind_kph': 15.1, 'wind_degree': 250, 'wind_dir': 'WSW', 'pressure_mb': 1019.0, 'pressure_in': 30.08, 'precip_mm': 0.0, 'precip_in': 0.0, 'humidity': 64, 'cloud': 0, 'feelslike_c': 21.1, 'feelslike_f': 70.0, 'windchill_c': 17.7, 'windchill_f': 63.8, 'heatindex_c': 17.7, 'heatindex_f': 63.8, 'dewpoint_c': 10.7, 'dewpoint_f': 51.2, 'vis_km': 16.0, 'vis_miles': 9.0, 'uv': 5.0, 'gust_mph': 13.2, 'gust_kph': 21.2}}\\\",\\\"score\\\":0.9991846,\\\"raw_content\\\":null}]\",\n", "        \"name\": \"tavily_search_results_json\",\n", "        \"additional_kwargs\": {},\n", "        \"response_metadata\": {}\n", "      }\n", "    ]\n", "  }\n", "}\n", "-----\n", "\n", "output {\n", "  agent: {\n", "    messages: [\n", "      AIMessageChunk {\n", "        \"id\": \"chatcmpl-9y36KCh1ZZbMNXVbLxTzz8jZb4t4T\",\n", "        \"content\": \"The current weather in San Francisco is sunny with a temperature of 70.0°F (21.1°C). The wind is blowing at 15.1 kph from the WSW direction. The humidity is at 64% and there is no precipitation.\",\n", "        \"additional_kwargs\": {},\n", "        \"response_metadata\": {\n", "          \"estimatedTokenUsage\": {\n", "            \"promptTokens\": 536,\n", "            \"completionTokens\": 53,\n", "            \"totalTokens\": 589\n", "          },\n", "          \"prompt\": 0,\n", "          \"completion\": 0,\n", "          \"finish_reason\": \"stop\",\n", "          \"system_fingerprint\": null\n", "        },\n", "        \"tool_calls\": [],\n", "        \"tool_call_chunks\": [],\n", "        \"invalid_tool_calls\": [],\n", "        \"usage_metadata\": {\n", "          \"input_tokens\": 538,\n", "          \"output_tokens\": 54,\n", "          \"total_tokens\": 592\n", "        }\n", "      }\n", "    ]\n", "  }\n", "}\n", "-----\n", "\n"]}], "source": ["for await (const output of await app.stream(inputs)) {\n", "  console.log(\"output\", output);\n", "  console.log(\"-----\\n\");\n", "}"]}], "metadata": {"kernelspec": {"display_name": "TypeScript", "language": "typescript", "name": "tslab"}, "language_info": {"codemirror_mode": {"mode": "typescript", "name": "javascript", "typescript": true}, "file_extension": ".ts", "mimetype": "text/typescript", "name": "typescript", "version": "3.7.2"}}, "nbformat": 4, "nbformat_minor": 5}